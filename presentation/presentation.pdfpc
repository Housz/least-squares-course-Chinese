{"pdfpcFormat":1,"disableMarkdown":true,"noteFontSize":10,"pages":[{"idx":0,"label":"0","overlay":0,"note":"Hello guys, I have a pleasure to present you our course entitled \"least squares for programmers\" that was prepared by Nicolas Ray, Étienne Corman and me, Dmitry Sokolov. We work in a research team named Pixel, and please feel free to contact us if you have any questions.\n\nIn this course we present how to manipulate geometric objects (curves, images, surfaces) by optimizing their characteristics using least squares methods; it is a very efficient tool that does not require too much of a mathematical background.\n\nThe title of states \"for programmers\", so please note that we have prepared a github repository that contains source code for all our examples. In addition to that, the course notes contain few (optional for reading) chapters that I will not present here, but that can be helpful to master the technology.\n"},{"idx":1,"label":"1","overlay":0,"note":"\nThis course is intended for students/engineers/researchers who know how to program in the traditional way: I mean by breaking down tasks into elementary operations that manipulate combinatorial structures (trees, graphs, meshes). Here we present a different paradigm: we describe what is a good result, and let numerical optimization find it for us.\n\nAnyone able to program computer graphics algorithms can learn how to use least squares with this course. It explains least squares optimization, nowadays a simple and well-mastered technology. We show how this simple method can solve a large number of problems that would be difficult to approach in any other way. This course provides a simple, understandable yet powerful tool that most coders can use, and I cannot stress this enough, in the contrast with other algorithms sharing this paradigm (numerical simulation and deep learning) which are more complex to master.\n\nThe importance of linear regression cannot be overstated. The most apparent usage of linear regression is in statistics / data analysis, but linear regression is much more than that. We propose to discover how the same method (least squares) applies to the manipulation of geometric objects. This first step into the numerical optimization world can be done without strong applied mathematics background; while being simple, this step suffices for many applications, and is a good starting point for learning more advanced algorithms.\n\nHere we strive to communicate the underlying intuitions through numerous examples of classic problems, we show different choices of variables and the ways the energies are built. Over the last two decades, the geometry processing community have used it for computing 2D maps, deformations, geodesic paths, frame fields, etc. Our examples provide many types of applications that can be directly solved by the least squares method.\n\nNote that linear regression is an efficient tool that has deep connections to other scientific domains; we will show a few such links to broaden attendees horizons.\n"},{"idx":2,"label":"2","overlay":0,"note":"The course is decomposed in three parts: an introduction of least squares, numerous use cases to demonstrate its usefulness, and the presentation of its strong relations to adjacent scientific domains:\n\nWe will start with a gentle introduction of the least squares method, providing some intuitions about linear systems.\n\nthen we proceed to the main course (this is about the section 4): how do we instantiate least squares to solve some problems? What can be the choice of variables? How to build the energy? How to deal with constraints? Are we bound by the linearity? This part is thoroughly illustrated with real examples and comes with simple source code that is meant to be experimented with.\n\n* The last part provides some insights about the strong connections between the fundamentals of least squares, probability theory, finite element methods and neural networks.\n"},{"idx":3,"label":"3","overlay":0,"note":"So, I'll start with the probability theory, this is a historical perspective, the orginis of least squares.\nLet us consider a simple example of coin flipping, also known as Bernoulli’s scheme. We conduct n experiments, two events can happen in each one (“success” or “failure”): one happens with probability p, the other\none with probability 1 − p. Our goal is to find the probability of getting exactly k successes in these n experiments.\n\nThis probability is given by Bernoulli’s formula.\n\nLet us take an ordinary coin (p = 1/2), flip it ten times (n = 10), and count how many times we get the tails. Thus, if we have fixed the probability of “success” (1/2) and also fixed the number of experiments (10), then the possible number of “successes” can be any integer between 0 and 10, but these outcomes are not equiprobable. It is clear that five “successes” are much more likely to happen than none. For example, the probability encountering seven tails is about 12%.\n\nIf we have a biased coin with probability p=0.7, the then probability of having 7 successes is about 27%.\n"},{"idx":4,"label":"3","overlay":1,"note":"So, I'll start with the probability theory, this is a historical perspective, the orginis of least squares.\nLet us consider a simple example of coin flipping, also known as Bernoulli’s scheme. We conduct n experiments, two events can happen in each one (“success” or “failure”): one happens with probability p, the other\none with probability 1 − p. Our goal is to find the probability of getting exactly k successes in these n experiments.\n\nThis probability is given by Bernoulli’s formula.\n\nLet us take an ordinary coin (p = 1/2), flip it ten times (n = 10), and count how many times we get the tails. Thus, if we have fixed the probability of “success” (1/2) and also fixed the number of experiments (10), then the possible number of “successes” can be any integer between 0 and 10, but these outcomes are not equiprobable. It is clear that five “successes” are much more likely to happen than none. For example, the probability encountering seven tails is about 12%.\n\nIf we have a biased coin with probability p=0.7, the then probability of having 7 successes is about 27%.\n"},{"idx":5,"label":"3","overlay":2,"note":"So, I'll start with the probability theory, this is a historical perspective, the orginis of least squares.\nLet us consider a simple example of coin flipping, also known as Bernoulli’s scheme. We conduct n experiments, two events can happen in each one (“success” or “failure”): one happens with probability p, the other\none with probability 1 − p. Our goal is to find the probability of getting exactly k successes in these n experiments.\n\nThis probability is given by Bernoulli’s formula.\n\nLet us take an ordinary coin (p = 1/2), flip it ten times (n = 10), and count how many times we get the tails. Thus, if we have fixed the probability of “success” (1/2) and also fixed the number of experiments (10), then the possible number of “successes” can be any integer between 0 and 10, but these outcomes are not equiprobable. It is clear that five “successes” are much more likely to happen than none. For example, the probability encountering seven tails is about 12%.\n\nIf we have a biased coin with probability p=0.7, the then probability of having 7 successes is about 27%.\n"},{"idx":6,"label":"3","overlay":3,"note":"So, I'll start with the probability theory, this is a historical perspective, the orginis of least squares.\nLet us consider a simple example of coin flipping, also known as Bernoulli’s scheme. We conduct n experiments, two events can happen in each one (“success” or “failure”): one happens with probability p, the other\none with probability 1 − p. Our goal is to find the probability of getting exactly k successes in these n experiments.\n\nThis probability is given by Bernoulli’s formula.\n\nLet us take an ordinary coin (p = 1/2), flip it ten times (n = 10), and count how many times we get the tails. Thus, if we have fixed the probability of “success” (1/2) and also fixed the number of experiments (10), then the possible number of “successes” can be any integer between 0 and 10, but these outcomes are not equiprobable. It is clear that five “successes” are much more likely to happen than none. For example, the probability encountering seven tails is about 12%.\n\nIf we have a biased coin with probability p=0.7, the then probability of having 7 successes is about 27%.\n"},{"idx":7,"label":"4","overlay":0,"note":"Now let us look at the same problem from a different angle. Suppose we have a real coin, but we do not know its distribution of a priori probability of “success”/“failure”. However, we can toss it ten times and\ncount the number of “successes”. For example, we have counted seven tails. Would it help us to evaluate p?\n\nWe can try to fix n = 10 and k = 7 in Bernoulli’s formula, leaving p as a free parameter. Please note that to ease visual parsing of the formulas, throughout all the presentation I highlight known values in green and uknown values in red.\n\nNow Bernoulli’s formula can be interpreted as the plausibility of the parameter p being evaluated. I have even changed the function notation, now it is denoted as L (likelihood).  That is being said, the likelihood is the probability to generate the observation data (7 tails out of 10 experiments) for the given value of the parameter(s). For example, the likelihood of a balanced coin (p = 1/2) with seven tails out of ten tosses is approximately 12%. Here is a plot of the likelihood function for the observation data with 7 tails out of 10 experiments.\n"},{"idx":8,"label":"4","overlay":1,"note":"Now let us look at the same problem from a different angle. Suppose we have a real coin, but we do not know its distribution of a priori probability of “success”/“failure”. However, we can toss it ten times and\ncount the number of “successes”. For example, we have counted seven tails. Would it help us to evaluate p?\n\nWe can try to fix n = 10 and k = 7 in Bernoulli’s formula, leaving p as a free parameter. Please note that to ease visual parsing of the formulas, throughout all the presentation I highlight known values in green and uknown values in red.\n\nNow Bernoulli’s formula can be interpreted as the plausibility of the parameter p being evaluated. I have even changed the function notation, now it is denoted as L (likelihood).  That is being said, the likelihood is the probability to generate the observation data (7 tails out of 10 experiments) for the given value of the parameter(s). For example, the likelihood of a balanced coin (p = 1/2) with seven tails out of ten tosses is approximately 12%. Here is a plot of the likelihood function for the observation data with 7 tails out of 10 experiments.\n"},{"idx":9,"label":"4","overlay":2,"note":"Now let us look at the same problem from a different angle. Suppose we have a real coin, but we do not know its distribution of a priori probability of “success”/“failure”. However, we can toss it ten times and\ncount the number of “successes”. For example, we have counted seven tails. Would it help us to evaluate p?\n\nWe can try to fix n = 10 and k = 7 in Bernoulli’s formula, leaving p as a free parameter. Please note that to ease visual parsing of the formulas, throughout all the presentation I highlight known values in green and uknown values in red.\n\nNow Bernoulli’s formula can be interpreted as the plausibility of the parameter p being evaluated. I have even changed the function notation, now it is denoted as L (likelihood).  That is being said, the likelihood is the probability to generate the observation data (7 tails out of 10 experiments) for the given value of the parameter(s). For example, the likelihood of a balanced coin (p = 1/2) with seven tails out of ten tosses is approximately 12%. Here is a plot of the likelihood function for the observation data with 7 tails out of 10 experiments.\n"},{"idx":10,"label":"5","overlay":0,"note":"Please note that this is a continuous graph.\nIf we have 7 tails out of 10 experiments, the probability to have a balanced coin is about 12%, and the most probable explanation for this experiment is to have the probability p=0.7.\nSo, having a model and an experiment, we are looking for the parameter value that maximizes the likelihood of producing the observations we have. In our particular case, we have a function of one variable, and we are looking for its maximum. In order to make things easier, I will not search for the maximum of L, but for the maximum of log L. The logarithm function is a strictly increasing function, so maximizing both is the same thing. The logarithm has a nice property of breaking down products into sums that are much more convenient to differentiate.\n\nSo, we are looking for the maximum of this function.\n\nThis is why we equate it’s derivative to zero. The derivative of log p = 1/p, so the equation is easy to solve.\nAs we have saw from the plot, The maximum likelihood (about 27%) is reached at the point p = 7/10 (well duh) \n\nJust in case, let us check the second derivative. In the point p = 7/10 it is negative, therefore this point is indeed a maximum of the function L.\n\nThe point of this exercice is to gently introduce a method of maximum likelihood estimation.\n\nThe point of this exercise is to gently introduce a method of maximum likelyhood estimation.\nThe idea is to estimate the parameters of a probability distribution by maximizing a likelihood function, so that under the assumed statistical model the observed data is the most probable.\n\nIf the likelihood function is differentiable, the derivative test for determining maxima can be applied. In some cases, like in one we have just saw, the first-order conditions of the likelihood function can be solved explicitly. As we will see shortly, the ordinary least squares estimator maximizes the likelihood of the linear regression model.\n"},{"idx":11,"label":"5","overlay":1,"note":"Please note that this is a continuous graph.\nIf we have 7 tails out of 10 experiments, the probability to have a balanced coin is about 12%, and the most probable explanation for this experiment is to have the probability p=0.7.\nSo, having a model and an experiment, we are looking for the parameter value that maximizes the likelihood of producing the observations we have. In our particular case, we have a function of one variable, and we are looking for its maximum. In order to make things easier, I will not search for the maximum of L, but for the maximum of log L. The logarithm function is a strictly increasing function, so maximizing both is the same thing. The logarithm has a nice property of breaking down products into sums that are much more convenient to differentiate.\n\nSo, we are looking for the maximum of this function.\n\nThis is why we equate it’s derivative to zero. The derivative of log p = 1/p, so the equation is easy to solve.\nAs we have saw from the plot, The maximum likelihood (about 27%) is reached at the point p = 7/10 (well duh) \n\nJust in case, let us check the second derivative. In the point p = 7/10 it is negative, therefore this point is indeed a maximum of the function L.\n\nThe point of this exercice is to gently introduce a method of maximum likelihood estimation.\n\nThe point of this exercise is to gently introduce a method of maximum likelyhood estimation.\nThe idea is to estimate the parameters of a probability distribution by maximizing a likelihood function, so that under the assumed statistical model the observed data is the most probable.\n\nIf the likelihood function is differentiable, the derivative test for determining maxima can be applied. In some cases, like in one we have just saw, the first-order conditions of the likelihood function can be solved explicitly. As we will see shortly, the ordinary least squares estimator maximizes the likelihood of the linear regression model.\n"},{"idx":12,"label":"5","overlay":2,"note":"Please note that this is a continuous graph.\nIf we have 7 tails out of 10 experiments, the probability to have a balanced coin is about 12%, and the most probable explanation for this experiment is to have the probability p=0.7.\nSo, having a model and an experiment, we are looking for the parameter value that maximizes the likelihood of producing the observations we have. In our particular case, we have a function of one variable, and we are looking for its maximum. In order to make things easier, I will not search for the maximum of L, but for the maximum of log L. The logarithm function is a strictly increasing function, so maximizing both is the same thing. The logarithm has a nice property of breaking down products into sums that are much more convenient to differentiate.\n\nSo, we are looking for the maximum of this function.\n\nThis is why we equate it’s derivative to zero. The derivative of log p = 1/p, so the equation is easy to solve.\nAs we have saw from the plot, The maximum likelihood (about 27%) is reached at the point p = 7/10 (well duh) \n\nJust in case, let us check the second derivative. In the point p = 7/10 it is negative, therefore this point is indeed a maximum of the function L.\n\nThe point of this exercice is to gently introduce a method of maximum likelihood estimation.\n\nThe point of this exercise is to gently introduce a method of maximum likelyhood estimation.\nThe idea is to estimate the parameters of a probability distribution by maximizing a likelihood function, so that under the assumed statistical model the observed data is the most probable.\n\nIf the likelihood function is differentiable, the derivative test for determining maxima can be applied. In some cases, like in one we have just saw, the first-order conditions of the likelihood function can be solved explicitly. As we will see shortly, the ordinary least squares estimator maximizes the likelihood of the linear regression model.\n"},{"idx":13,"label":"5","overlay":3,"note":"Please note that this is a continuous graph.\nIf we have 7 tails out of 10 experiments, the probability to have a balanced coin is about 12%, and the most probable explanation for this experiment is to have the probability p=0.7.\nSo, having a model and an experiment, we are looking for the parameter value that maximizes the likelihood of producing the observations we have. In our particular case, we have a function of one variable, and we are looking for its maximum. In order to make things easier, I will not search for the maximum of L, but for the maximum of log L. The logarithm function is a strictly increasing function, so maximizing both is the same thing. The logarithm has a nice property of breaking down products into sums that are much more convenient to differentiate.\n\nSo, we are looking for the maximum of this function.\n\nThis is why we equate it’s derivative to zero. The derivative of log p = 1/p, so the equation is easy to solve.\nAs we have saw from the plot, The maximum likelihood (about 27%) is reached at the point p = 7/10 (well duh) \n\nJust in case, let us check the second derivative. In the point p = 7/10 it is negative, therefore this point is indeed a maximum of the function L.\n\nThe point of this exercice is to gently introduce a method of maximum likelihood estimation.\n\nThe point of this exercise is to gently introduce a method of maximum likelyhood estimation.\nThe idea is to estimate the parameters of a probability distribution by maximizing a likelihood function, so that under the assumed statistical model the observed data is the most probable.\n\nIf the likelihood function is differentiable, the derivative test for determining maxima can be applied. In some cases, like in one we have just saw, the first-order conditions of the likelihood function can be solved explicitly. As we will see shortly, the ordinary least squares estimator maximizes the likelihood of the linear regression model.\n"},{"idx":14,"label":"5","overlay":4,"note":"Please note that this is a continuous graph.\nIf we have 7 tails out of 10 experiments, the probability to have a balanced coin is about 12%, and the most probable explanation for this experiment is to have the probability p=0.7.\nSo, having a model and an experiment, we are looking for the parameter value that maximizes the likelihood of producing the observations we have. In our particular case, we have a function of one variable, and we are looking for its maximum. In order to make things easier, I will not search for the maximum of L, but for the maximum of log L. The logarithm function is a strictly increasing function, so maximizing both is the same thing. The logarithm has a nice property of breaking down products into sums that are much more convenient to differentiate.\n\nSo, we are looking for the maximum of this function.\n\nThis is why we equate it’s derivative to zero. The derivative of log p = 1/p, so the equation is easy to solve.\nAs we have saw from the plot, The maximum likelihood (about 27%) is reached at the point p = 7/10 (well duh) \n\nJust in case, let us check the second derivative. In the point p = 7/10 it is negative, therefore this point is indeed a maximum of the function L.\n\nThe point of this exercice is to gently introduce a method of maximum likelihood estimation.\n\nThe point of this exercise is to gently introduce a method of maximum likelyhood estimation.\nThe idea is to estimate the parameters of a probability distribution by maximizing a likelihood function, so that under the assumed statistical model the observed data is the most probable.\n\nIf the likelihood function is differentiable, the derivative test for determining maxima can be applied. In some cases, like in one we have just saw, the first-order conditions of the likelihood function can be solved explicitly. As we will see shortly, the ordinary least squares estimator maximizes the likelihood of the linear regression model.\n"},{"idx":15,"label":"6","overlay":0,"note":"Let us imagine that we have a constant physical quantity that we want to measure; for example, it can be a\nlength to measure with a ruler or a voltage with a voltmeter. In the real world, any measurement gives only an\napproximation of this value, but not the value itself. The methods I am describing here were developed by\nGauß at the end of the 18th century, when he measured the orbits of celestial bodies.\n\nFor example, if we measure the battery voltage N times, we get N different measurements. Which of\nthem should we take? All of them! So, let us say that we have N measurements Uj.\n\nLet us suppose that each measurement Uj is equal to the real value plus a Gaussian noise. The noise\nis characterized by two parameters — the center of the Gaussian bell and its “width”. In this case, the\nprobability density can be expressed as an exponent function.\n"},{"idx":16,"label":"7","overlay":0,"note":"Having N measurements Uj , our goal is to find the parameters U and σ that maximize the likelihood. The likelihood (I have already applied the logarithm) can be written as follows, here we use our assumption that the measurements are independent and identically distributed.\n\n[show the math]\n\nWe can conclude that under Gaussian noise maximization of the likelihood is equivalent to a least squares minimization.\n"},{"idx":17,"label":"7","overlay":1,"note":"Having N measurements Uj , our goal is to find the parameters U and σ that maximize the likelihood. The likelihood (I have already applied the logarithm) can be written as follows, here we use our assumption that the measurements are independent and identically distributed.\n\n[show the math]\n\nWe can conclude that under Gaussian noise maximization of the likelihood is equivalent to a least squares minimization.\n"},{"idx":18,"label":"7","overlay":2,"note":"Having N measurements Uj , our goal is to find the parameters U and σ that maximize the likelihood. The likelihood (I have already applied the logarithm) can be written as follows, here we use our assumption that the measurements are independent and identically distributed.\n\n[show the math]\n\nWe can conclude that under Gaussian noise maximization of the likelihood is equivalent to a least squares minimization.\n"},{"idx":19,"label":"7","overlay":3,"note":"Having N measurements Uj , our goal is to find the parameters U and σ that maximize the likelihood. The likelihood (I have already applied the logarithm) can be written as follows, here we use our assumption that the measurements are independent and identically distributed.\n\n[show the math]\n\nWe can conclude that under Gaussian noise maximization of the likelihood is equivalent to a least squares minimization.\n"},{"idx":20,"label":"8","overlay":0,"note":"And then everything is strictly as it used to be, we equate the partial derivatives to zero.\n\nIt is easy to see that the most plausible estimation of the unknown value U is the simple average of all measurements.\n\nAnd the most plausible estimation of σ turns out to be the standard deviation.\n\nSuch a convoluted way to obtain a simple average of all measurements. . . In my humble opinion, the result\nis worth the effort. By the way, averaging multiple measurements of a constant value in order to increase\nthe accuracy of measurements is quite a standard practice. For example, ADC averaging. Note that the\nhypothesis of Gaussian noise is not necessary in this case, it is enough to have an unbiased noise.\n"},{"idx":21,"label":"8","overlay":1,"note":"And then everything is strictly as it used to be, we equate the partial derivatives to zero.\n\nIt is easy to see that the most plausible estimation of the unknown value U is the simple average of all measurements.\n\nAnd the most plausible estimation of σ turns out to be the standard deviation.\n\nSuch a convoluted way to obtain a simple average of all measurements. . . In my humble opinion, the result\nis worth the effort. By the way, averaging multiple measurements of a constant value in order to increase\nthe accuracy of measurements is quite a standard practice. For example, ADC averaging. Note that the\nhypothesis of Gaussian noise is not necessary in this case, it is enough to have an unbiased noise.\n"},{"idx":22,"label":"8","overlay":2,"note":"And then everything is strictly as it used to be, we equate the partial derivatives to zero.\n\nIt is easy to see that the most plausible estimation of the unknown value U is the simple average of all measurements.\n\nAnd the most plausible estimation of σ turns out to be the standard deviation.\n\nSuch a convoluted way to obtain a simple average of all measurements. . . In my humble opinion, the result\nis worth the effort. By the way, averaging multiple measurements of a constant value in order to increase\nthe accuracy of measurements is quite a standard practice. For example, ADC averaging. Note that the\nhypothesis of Gaussian noise is not necessary in this case, it is enough to have an unbiased noise.\n"},{"idx":23,"label":"8","overlay":3,"note":"And then everything is strictly as it used to be, we equate the partial derivatives to zero.\n\nIt is easy to see that the most plausible estimation of the unknown value U is the simple average of all measurements.\n\nAnd the most plausible estimation of σ turns out to be the standard deviation.\n\nSuch a convoluted way to obtain a simple average of all measurements. . . In my humble opinion, the result\nis worth the effort. By the way, averaging multiple measurements of a constant value in order to increase\nthe accuracy of measurements is quite a standard practice. For example, ADC averaging. Note that the\nhypothesis of Gaussian noise is not necessary in this case, it is enough to have an unbiased noise.\n"},{"idx":24,"label":"9","overlay":0,"note":"While we have seen that for measuring a constant value it suffices to take a simple average to get the most plausible explanation, it is much harder for less trivial  cases.\n\nLet us consider the last example, here we are talking about ordinary least squares. Say we want to calibrate a spring scale with a help of reference weights. Suppose we have N reference weights of mass xj ; we weigh them with the scale and measure the length of the spring. So, we have N spring lengths yj.\n\nHooke’s law tells us that spring stretches linearly on the force applied; this force includes the reference\nweight and the weight of the spring itself. Let us denote the spring stiffness as a, and the spring length\nstreched under under its own weight as b. Then we can express the plausibility of our measurements (still\nunder the Gaussian measurement noise hypothesis) in this way:\n\nMaximizing the likelihood of L is equivalent to minimizing the sum of the squared estimation error.\n\n"},{"idx":25,"label":"9","overlay":1,"note":"While we have seen that for measuring a constant value it suffices to take a simple average to get the most plausible explanation, it is much harder for less trivial  cases.\n\nLet us consider the last example, here we are talking about ordinary least squares. Say we want to calibrate a spring scale with a help of reference weights. Suppose we have N reference weights of mass xj ; we weigh them with the scale and measure the length of the spring. So, we have N spring lengths yj.\n\nHooke’s law tells us that spring stretches linearly on the force applied; this force includes the reference\nweight and the weight of the spring itself. Let us denote the spring stiffness as a, and the spring length\nstreched under under its own weight as b. Then we can express the plausibility of our measurements (still\nunder the Gaussian measurement noise hypothesis) in this way:\n\nMaximizing the likelihood of L is equivalent to minimizing the sum of the squared estimation error.\n\n"},{"idx":26,"label":"9","overlay":2,"note":"While we have seen that for measuring a constant value it suffices to take a simple average to get the most plausible explanation, it is much harder for less trivial  cases.\n\nLet us consider the last example, here we are talking about ordinary least squares. Say we want to calibrate a spring scale with a help of reference weights. Suppose we have N reference weights of mass xj ; we weigh them with the scale and measure the length of the spring. So, we have N spring lengths yj.\n\nHooke’s law tells us that spring stretches linearly on the force applied; this force includes the reference\nweight and the weight of the spring itself. Let us denote the spring stiffness as a, and the spring length\nstreched under under its own weight as b. Then we can express the plausibility of our measurements (still\nunder the Gaussian measurement noise hypothesis) in this way:\n\nMaximizing the likelihood of L is equivalent to minimizing the sum of the squared estimation error.\n\n"},{"idx":27,"label":"10","overlay":0,"note":"Thus, we are looking for the minimum of the function S defined as follows:\n\nThe image on the right illustrates the formula: we are looking for such a straight line that minimizes the sum of\nsquared lengths of green segments. And then the derivation is quite straightforward. We equate the partial derivatives to zero.\n\nWe obtain a system of two linear equations with two unknowns, and we can use any method to get the solution.\n\n\n"},{"idx":28,"label":"10","overlay":1,"note":"Thus, we are looking for the minimum of the function S defined as follows:\n\nThe image on the right illustrates the formula: we are looking for such a straight line that minimizes the sum of\nsquared lengths of green segments. And then the derivation is quite straightforward. We equate the partial derivatives to zero.\n\nWe obtain a system of two linear equations with two unknowns, and we can use any method to get the solution.\n\n\n"},{"idx":29,"label":"10","overlay":2,"note":"Thus, we are looking for the minimum of the function S defined as follows:\n\nThe image on the right illustrates the formula: we are looking for such a straight line that minimizes the sum of\nsquared lengths of green segments. And then the derivation is quite straightforward. We equate the partial derivatives to zero.\n\nWe obtain a system of two linear equations with two unknowns, and we can use any method to get the solution.\n\n\n"},{"idx":30,"label":"11","overlay":0,"note":"The idea of behind this section was to give some historical perspective.\n\nThe least squares method is a particular case of maximizing likelihood in cases where the probability density\nis Gaussian. If the density is not Gaussian, the least squares approach can produce an estimate different\nfrom the MLE (maximum likelihood estimation). \n\nBy the way, Gauß erroneously conjectured that the type of noise is of no importance, and the only thing that matters is the independence of trials.\n\nAs you have already noticed, the more parameters we have, the more cumbersome the analytical solutions\nare. Fortunately, we are not living in XVIII century anymore, we have computers! \n\nNext we will try to build a geometric intuition on least squares, and see how can least squares problems be efficiently implemented.\n"},{"idx":31,"label":"12","overlay":0,"note":"I have promised \"for programmers\" in the course title, and we have not seen a single line of code yet! It is time to change that. \n\nIn the last example we had to solve a 2x2 linear system, so before attacking larger least squares with an aid of a computer, we need to recall how to solve systems of linear equations, and to do so, we will write our first program.\n"},{"idx":32,"label":"13","overlay":0,"note":"Let us examine the following Python program.\n\nWe start from a 16 elements array, and we iterate over and over a simple procedure: \nwe replace each element with an average of its neighbours; the first and the last elements are fixed.\n\nHere is a quick test. What should we get in the end? Does it converge or oscillate infinitely?\n\nTake few seconds.\n\nIntuitively, each peak in the array is cut out, and therefore the array will be smoothed over time.\n\nHere is the evolution of the data over time.\n\nIs there a way to predict the result without guessing it and without executing the program?\nThe answer is yes; let us put the program aside for a moment and recall how to solve systems of linear equations.\n"},{"idx":33,"label":"13","overlay":1,"note":"Let us examine the following Python program.\n\nWe start from a 16 elements array, and we iterate over and over a simple procedure: \nwe replace each element with an average of its neighbours; the first and the last elements are fixed.\n\nHere is a quick test. What should we get in the end? Does it converge or oscillate infinitely?\n\nTake few seconds.\n\nIntuitively, each peak in the array is cut out, and therefore the array will be smoothed over time.\n\nHere is the evolution of the data over time.\n\nIs there a way to predict the result without guessing it and without executing the program?\nThe answer is yes; let us put the program aside for a moment and recall how to solve systems of linear equations.\n"},{"idx":34,"label":"13","overlay":2,"note":"Let us examine the following Python program.\n\nWe start from a 16 elements array, and we iterate over and over a simple procedure: \nwe replace each element with an average of its neighbours; the first and the last elements are fixed.\n\nHere is a quick test. What should we get in the end? Does it converge or oscillate infinitely?\n\nTake few seconds.\n\nIntuitively, each peak in the array is cut out, and therefore the array will be smoothed over time.\n\nHere is the evolution of the data over time.\n\nIs there a way to predict the result without guessing it and without executing the program?\nThe answer is yes; let us put the program aside for a moment and recall how to solve systems of linear equations.\n"},{"idx":35,"label":"13","overlay":3,"note":"Let us examine the following Python program.\n\nWe start from a 16 elements array, and we iterate over and over a simple procedure: \nwe replace each element with an average of its neighbours; the first and the last elements are fixed.\n\nHere is a quick test. What should we get in the end? Does it converge or oscillate infinitely?\n\nTake few seconds.\n\nIntuitively, each peak in the array is cut out, and therefore the array will be smoothed over time.\n\nHere is the evolution of the data over time.\n\nIs there a way to predict the result without guessing it and without executing the program?\nThe answer is yes; let us put the program aside for a moment and recall how to solve systems of linear equations.\n"},{"idx":36,"label":"13","overlay":4,"note":"Let us examine the following Python program.\n\nWe start from a 16 elements array, and we iterate over and over a simple procedure: \nwe replace each element with an average of its neighbours; the first and the last elements are fixed.\n\nHere is a quick test. What should we get in the end? Does it converge or oscillate infinitely?\n\nTake few seconds.\n\nIntuitively, each peak in the array is cut out, and therefore the array will be smoothed over time.\n\nHere is the evolution of the data over time.\n\nIs there a way to predict the result without guessing it and without executing the program?\nThe answer is yes; let us put the program aside for a moment and recall how to solve systems of linear equations.\n"},{"idx":37,"label":"13","overlay":5,"note":"Let us examine the following Python program.\n\nWe start from a 16 elements array, and we iterate over and over a simple procedure: \nwe replace each element with an average of its neighbours; the first and the last elements are fixed.\n\nHere is a quick test. What should we get in the end? Does it converge or oscillate infinitely?\n\nTake few seconds.\n\nIntuitively, each peak in the array is cut out, and therefore the array will be smoothed over time.\n\nHere is the evolution of the data over time.\n\nIs there a way to predict the result without guessing it and without executing the program?\nThe answer is yes; let us put the program aside for a moment and recall how to solve systems of linear equations.\n"},{"idx":38,"label":"14","overlay":0,"note":"Let us suppose that we have an ordinary system of linear equations.\n\nIt can be rewritten by leaving the x_i at the left side of the equations.\n"},{"idx":39,"label":"14","overlay":1,"note":"Let us suppose that we have an ordinary system of linear equations.\n\nIt can be rewritten by leaving the x_i at the left side of the equations.\n"},{"idx":40,"label":"15","overlay":0,"note":"Suppose that we have an arbitrary vector x0 approximating the solution, for example, a zero vector.\nThen, if we plug it into the right side of the equations, we can compue an updated approximation x1.\n\nThus, we build a sequence of approximations, and under some assumptions on the system, this procedure converges to the true solution. This iteration is known as the Jacobi method. Of course, there are other much more powerful numerical methods, but this is the simplest one.\n"},{"idx":41,"label":"15","overlay":1,"note":"Suppose that we have an arbitrary vector x0 approximating the solution, for example, a zero vector.\nThen, if we plug it into the right side of the equations, we can compue an updated approximation x1.\n\nThus, we build a sequence of approximations, and under some assumptions on the system, this procedure converges to the true solution. This iteration is known as the Jacobi method. Of course, there are other much more powerful numerical methods, but this is the simplest one.\n"},{"idx":42,"label":"15","overlay":2,"note":"Suppose that we have an arbitrary vector x0 approximating the solution, for example, a zero vector.\nThen, if we plug it into the right side of the equations, we can compue an updated approximation x1.\n\nThus, we build a sequence of approximations, and under some assumptions on the system, this procedure converges to the true solution. This iteration is known as the Jacobi method. Of course, there are other much more powerful numerical methods, but this is the simplest one.\n"},{"idx":43,"label":"16","overlay":0,"note":"What is the connection to our python program?\n\nIn fact, we replace each interior node x_i with the average of its values that can be rewritten as follows.\n\nIt turns out that the program solves the following system with the Jacobi method.\n\nSince you can pause the video, do not take my word for it, grab a pencil and verify it! \n\nSo, if we consider the array as a sampled function, the linear system prescribes a constant derivative and fixes the extremities, therefore the result can only be a straight line.\n"},{"idx":44,"label":"16","overlay":1,"note":"What is the connection to our python program?\n\nIn fact, we replace each interior node x_i with the average of its values that can be rewritten as follows.\n\nIt turns out that the program solves the following system with the Jacobi method.\n\nSince you can pause the video, do not take my word for it, grab a pencil and verify it! \n\nSo, if we consider the array as a sampled function, the linear system prescribes a constant derivative and fixes the extremities, therefore the result can only be a straight line.\n"},{"idx":45,"label":"16","overlay":2,"note":"What is the connection to our python program?\n\nIn fact, we replace each interior node x_i with the average of its values that can be rewritten as follows.\n\nIt turns out that the program solves the following system with the Jacobi method.\n\nSince you can pause the video, do not take my word for it, grab a pencil and verify it! \n\nSo, if we consider the array as a sampled function, the linear system prescribes a constant derivative and fixes the extremities, therefore the result can only be a straight line.\n"},{"idx":46,"label":"16","overlay":3,"note":"What is the connection to our python program?\n\nIn fact, we replace each interior node x_i with the average of its values that can be rewritten as follows.\n\nIt turns out that the program solves the following system with the Jacobi method.\n\nSince you can pause the video, do not take my word for it, grab a pencil and verify it! \n\nSo, if we consider the array as a sampled function, the linear system prescribes a constant derivative and fixes the extremities, therefore the result can only be a straight line.\n"},{"idx":47,"label":"17","overlay":0,"note":"There is a very interesting modification of the Jacobi method, named after Johann Carl Friedrich Gauß\nand Philipp Ludwig von Seidel. This modification is even easier to implement than the Jacobi method,\nand it often requires fewer iterations to produce the same degree of accuracy. With the Jacobi method, the\nvalues of obtained in the k-th approximation remain unchanged until the entire k-th approximation has been\ncalculated. \n\nWith the Gauß-Seidel method, on the other hand, we use the new values of each as soon as they\nare known.\n"},{"idx":48,"label":"17","overlay":1,"note":"There is a very interesting modification of the Jacobi method, named after Johann Carl Friedrich Gauß\nand Philipp Ludwig von Seidel. This modification is even easier to implement than the Jacobi method,\nand it often requires fewer iterations to produce the same degree of accuracy. With the Jacobi method, the\nvalues of obtained in the k-th approximation remain unchanged until the entire k-th approximation has been\ncalculated. \n\nWith the Gauß-Seidel method, on the other hand, we use the new values of each as soon as they\nare known.\n"},{"idx":49,"label":"18","overlay":0,"note":"The recursive formulas can be written as follows\n\nIt allows to perform all the computations in place. \n"},{"idx":50,"label":"18","overlay":1,"note":"The recursive formulas can be written as follows\n\nIt allows to perform all the computations in place. \n"},{"idx":55,"label":"22","overlay":0,"note":"[draw a 1-ring]\n\nInterestingly, it is all the same for our 3D surface, the above code solves the Laplace’s equation ∆f = 0 with Dirichlet\nboundary conditions. Again, do not trust me, grab a pencil and write down the corresponding matrix\nfor a mesh with one interior vertex. Actually, let us do it together.\n\n\nSo, the result must be the minimal surface respecting the boundary conditions. In other words, make a loop from a rigid wire, soak it in a liqud soap, the soap film on this loop is the solution. \n"},{"idx":56,"label":"22","overlay":1,"note":"[draw a 1-ring]\n\nInterestingly, it is all the same for our 3D surface, the above code solves the Laplace’s equation ∆f = 0 with Dirichlet\nboundary conditions. Again, do not trust me, grab a pencil and write down the corresponding matrix\nfor a mesh with one interior vertex. Actually, let us do it together.\n\n\nSo, the result must be the minimal surface respecting the boundary conditions. In other words, make a loop from a rigid wire, soak it in a liqud soap, the soap film on this loop is the solution. \n"},{"idx":57,"label":"23","overlay":0,"note":"[Another quiz]\n\nWhat is the result of this program? Well, it is easy to answer. We are looking for a function whose\nsecond derivative is a linear function, therefore the solution must be a cubic polynomial. Here you can see\nthe evolution of the array, the ground truth polynomial is shown in green.\nCongratulations, you have just solved a Poisson’s equation!\n"},{"idx":58,"label":"23","overlay":1,"note":"[Another quiz]\n\nWhat is the result of this program? Well, it is easy to answer. We are looking for a function whose\nsecond derivative is a linear function, therefore the solution must be a cubic polynomial. Here you can see\nthe evolution of the array, the ground truth polynomial is shown in green.\nCongratulations, you have just solved a Poisson’s equation!\n"},{"idx":60,"label":"25","overlay":0,"note":"Recall that the main goal is to study least squares, therefore our main tool will be the minimization of\nquadratic functions; however, before we start using this power tool, we need to find where its on/off button\nis located. First of all, we need to recall what a matrix is; then we will revisit the definition of a positive\nnumbers, and only then we will attack minimization of quadratic functions.\n"},{"idx":61,"label":"26","overlay":0,"note":"In this sections, matrices will be omnipresent, so let’s remember what it is. Pause the video for a few seconds, and try to formulate what the matrix is.\n\nThe answer is very simple. A matrix is just a locker that stores stuff. Each piece of stuff lies in its own cell,\ncells are grouped in rows and columns. In our particular case, we store real numbers; for a programmer the\neasiest way to imagine a matrix A is something like:\nfloat A[m][n];\n\nWhy would we need a storage like this? What does it describe? Maybe I will upset you, but the matrix\nby itself does not describe anything, it stores stuff. For example, you can store coefficients of a function in\nit. Let us put aside matrices for a second imagine that we have a number a. What does it mean? Who\nknows what it means. . . \n\nFor example, it can be a coefficient inside a function that takes one number as an\ninput and gives another number as an output. One possible instance of such a function a mathematicion could write down as: f (x) = ax\n\nIn the programmers’ world it would look something like this:\n\nOn the other hand, why this function and not another one? Let’s take another one!\n\nf (x) = ax2\n\nA programmer would write it like this:\n\nOne of these functions is linear and the other is quadratic. Which one is correct? Neither one. The\nnumber a does not define it, it just stores a value! Build the function you need.\n"},{"idx":62,"label":"26","overlay":1,"note":"In this sections, matrices will be omnipresent, so let’s remember what it is. Pause the video for a few seconds, and try to formulate what the matrix is.\n\nThe answer is very simple. A matrix is just a locker that stores stuff. Each piece of stuff lies in its own cell,\ncells are grouped in rows and columns. In our particular case, we store real numbers; for a programmer the\neasiest way to imagine a matrix A is something like:\nfloat A[m][n];\n\nWhy would we need a storage like this? What does it describe? Maybe I will upset you, but the matrix\nby itself does not describe anything, it stores stuff. For example, you can store coefficients of a function in\nit. Let us put aside matrices for a second imagine that we have a number a. What does it mean? Who\nknows what it means. . . \n\nFor example, it can be a coefficient inside a function that takes one number as an\ninput and gives another number as an output. One possible instance of such a function a mathematicion could write down as: f (x) = ax\n\nIn the programmers’ world it would look something like this:\n\nOn the other hand, why this function and not another one? Let’s take another one!\n\nf (x) = ax2\n\nA programmer would write it like this:\n\nOne of these functions is linear and the other is quadratic. Which one is correct? Neither one. The\nnumber a does not define it, it just stores a value! Build the function you need.\n"},{"idx":63,"label":"26","overlay":2,"note":"In this sections, matrices will be omnipresent, so let’s remember what it is. Pause the video for a few seconds, and try to formulate what the matrix is.\n\nThe answer is very simple. A matrix is just a locker that stores stuff. Each piece of stuff lies in its own cell,\ncells are grouped in rows and columns. In our particular case, we store real numbers; for a programmer the\neasiest way to imagine a matrix A is something like:\nfloat A[m][n];\n\nWhy would we need a storage like this? What does it describe? Maybe I will upset you, but the matrix\nby itself does not describe anything, it stores stuff. For example, you can store coefficients of a function in\nit. Let us put aside matrices for a second imagine that we have a number a. What does it mean? Who\nknows what it means. . . \n\nFor example, it can be a coefficient inside a function that takes one number as an\ninput and gives another number as an output. One possible instance of such a function a mathematicion could write down as: f (x) = ax\n\nIn the programmers’ world it would look something like this:\n\nOn the other hand, why this function and not another one? Let’s take another one!\n\nf (x) = ax2\n\nA programmer would write it like this:\n\nOne of these functions is linear and the other is quadratic. Which one is correct? Neither one. The\nnumber a does not define it, it just stores a value! Build the function you need.\n"},{"idx":64,"label":"26","overlay":3,"note":"In this sections, matrices will be omnipresent, so let’s remember what it is. Pause the video for a few seconds, and try to formulate what the matrix is.\n\nThe answer is very simple. A matrix is just a locker that stores stuff. Each piece of stuff lies in its own cell,\ncells are grouped in rows and columns. In our particular case, we store real numbers; for a programmer the\neasiest way to imagine a matrix A is something like:\nfloat A[m][n];\n\nWhy would we need a storage like this? What does it describe? Maybe I will upset you, but the matrix\nby itself does not describe anything, it stores stuff. For example, you can store coefficients of a function in\nit. Let us put aside matrices for a second imagine that we have a number a. What does it mean? Who\nknows what it means. . . \n\nFor example, it can be a coefficient inside a function that takes one number as an\ninput and gives another number as an output. One possible instance of such a function a mathematicion could write down as: f (x) = ax\n\nIn the programmers’ world it would look something like this:\n\nOn the other hand, why this function and not another one? Let’s take another one!\n\nf (x) = ax2\n\nA programmer would write it like this:\n\nOne of these functions is linear and the other is quadratic. Which one is correct? Neither one. The\nnumber a does not define it, it just stores a value! Build the function you need.\n"},{"idx":65,"label":"26","overlay":4,"note":"In this sections, matrices will be omnipresent, so let’s remember what it is. Pause the video for a few seconds, and try to formulate what the matrix is.\n\nThe answer is very simple. A matrix is just a locker that stores stuff. Each piece of stuff lies in its own cell,\ncells are grouped in rows and columns. In our particular case, we store real numbers; for a programmer the\neasiest way to imagine a matrix A is something like:\nfloat A[m][n];\n\nWhy would we need a storage like this? What does it describe? Maybe I will upset you, but the matrix\nby itself does not describe anything, it stores stuff. For example, you can store coefficients of a function in\nit. Let us put aside matrices for a second imagine that we have a number a. What does it mean? Who\nknows what it means. . . \n\nFor example, it can be a coefficient inside a function that takes one number as an\ninput and gives another number as an output. One possible instance of such a function a mathematicion could write down as: f (x) = ax\n\nIn the programmers’ world it would look something like this:\n\nOn the other hand, why this function and not another one? Let’s take another one!\n\nf (x) = ax2\n\nA programmer would write it like this:\n\nOne of these functions is linear and the other is quadratic. Which one is correct? Neither one. The\nnumber a does not define it, it just stores a value! Build the function you need.\n"},{"idx":66,"label":"27","overlay":0,"note":"The same thing happens to matrices, they give storage space when simple numbers (scalars) do not\nsuffice, a matrix is a sort of an hyper-number. The addition and multiplication operations are defined over\nmatrices just as over numbers.\n\nLet us suppose that we have a 2 × 2 matrix A:\n\nThe matrix does not mean anything by itself, for example, it can be interpreted as a linear function:\nHere goes the programmer’s view on the function. This function maps a two-dimensional vector to a two-dimensional vector. Graphically, it is convenient to imagine it as an image transformation: we give an input image, and the output is the stretched and/or rotated (maybe even mirrored!) version. \n\nOn the other hand, nothing prevents to interpret the matrix A as a quadratic function that maps a vector to a\nscalar. Note that the square is not very well defined for the vectors, so I cannot write x^2 as I wrote in the case\nof ordinary numbers. For those who are not at ease with matrix multiplications, I highly recommend to\nrevisit it right now and check that the expression x^tAx indeed produces a scalar value. To this end, we\ncan explicitly put brackets x^tAx = (x^tA)x. Recall that in this particular example x is a two-dimensional\nvector (stored in a 2 × 1 matrix). Let us write all the matrix dimensions explicitly:\n\nReturning to the cozy world of programmers, we can write the same quadratic function as shown in the bottom of the slide.\n"},{"idx":67,"label":"27","overlay":1,"note":"The same thing happens to matrices, they give storage space when simple numbers (scalars) do not\nsuffice, a matrix is a sort of an hyper-number. The addition and multiplication operations are defined over\nmatrices just as over numbers.\n\nLet us suppose that we have a 2 × 2 matrix A:\n\nThe matrix does not mean anything by itself, for example, it can be interpreted as a linear function:\nHere goes the programmer’s view on the function. This function maps a two-dimensional vector to a two-dimensional vector. Graphically, it is convenient to imagine it as an image transformation: we give an input image, and the output is the stretched and/or rotated (maybe even mirrored!) version. \n\nOn the other hand, nothing prevents to interpret the matrix A as a quadratic function that maps a vector to a\nscalar. Note that the square is not very well defined for the vectors, so I cannot write x^2 as I wrote in the case\nof ordinary numbers. For those who are not at ease with matrix multiplications, I highly recommend to\nrevisit it right now and check that the expression x^tAx indeed produces a scalar value. To this end, we\ncan explicitly put brackets x^tAx = (x^tA)x. Recall that in this particular example x is a two-dimensional\nvector (stored in a 2 × 1 matrix). Let us write all the matrix dimensions explicitly:\n\nReturning to the cozy world of programmers, we can write the same quadratic function as shown in the bottom of the slide.\n"},{"idx":68,"label":"27","overlay":2,"note":"The same thing happens to matrices, they give storage space when simple numbers (scalars) do not\nsuffice, a matrix is a sort of an hyper-number. The addition and multiplication operations are defined over\nmatrices just as over numbers.\n\nLet us suppose that we have a 2 × 2 matrix A:\n\nThe matrix does not mean anything by itself, for example, it can be interpreted as a linear function:\nHere goes the programmer’s view on the function. This function maps a two-dimensional vector to a two-dimensional vector. Graphically, it is convenient to imagine it as an image transformation: we give an input image, and the output is the stretched and/or rotated (maybe even mirrored!) version. \n\nOn the other hand, nothing prevents to interpret the matrix A as a quadratic function that maps a vector to a\nscalar. Note that the square is not very well defined for the vectors, so I cannot write x^2 as I wrote in the case\nof ordinary numbers. For those who are not at ease with matrix multiplications, I highly recommend to\nrevisit it right now and check that the expression x^tAx indeed produces a scalar value. To this end, we\ncan explicitly put brackets x^tAx = (x^tA)x. Recall that in this particular example x is a two-dimensional\nvector (stored in a 2 × 1 matrix). Let us write all the matrix dimensions explicitly:\n\nReturning to the cozy world of programmers, we can write the same quadratic function as shown in the bottom of the slide.\n"},{"idx":69,"label":"27","overlay":3,"note":"The same thing happens to matrices, they give storage space when simple numbers (scalars) do not\nsuffice, a matrix is a sort of an hyper-number. The addition and multiplication operations are defined over\nmatrices just as over numbers.\n\nLet us suppose that we have a 2 × 2 matrix A:\n\nThe matrix does not mean anything by itself, for example, it can be interpreted as a linear function:\nHere goes the programmer’s view on the function. This function maps a two-dimensional vector to a two-dimensional vector. Graphically, it is convenient to imagine it as an image transformation: we give an input image, and the output is the stretched and/or rotated (maybe even mirrored!) version. \n\nOn the other hand, nothing prevents to interpret the matrix A as a quadratic function that maps a vector to a\nscalar. Note that the square is not very well defined for the vectors, so I cannot write x^2 as I wrote in the case\nof ordinary numbers. For those who are not at ease with matrix multiplications, I highly recommend to\nrevisit it right now and check that the expression x^tAx indeed produces a scalar value. To this end, we\ncan explicitly put brackets x^tAx = (x^tA)x. Recall that in this particular example x is a two-dimensional\nvector (stored in a 2 × 1 matrix). Let us write all the matrix dimensions explicitly:\n\nReturning to the cozy world of programmers, we can write the same quadratic function as shown in the bottom of the slide.\n"},{"idx":70,"label":"28","overlay":0,"note":"Allow me to ask a very stupid question: what is a positive number? We have a great tool called the predicate\n“greater than” >. Do not be in a hurry to answer that the number a is positive if and only if a > 0, it would\nbe too easy. Let us define the positivity as follows:\n\nThe real number a is positive if and only if for all non-zero real x ∈ R, x != 0 the condition ax^2 > 0 is satisfied.\n\nThis definition looks pretty awkward, but it applies perfectly to matrices:\n\nA square matrix A is called positive definite if for any non-zero x the condition x^t Ax > 0\nis met, i.e. the corresponding quadratic form is strictly positive everywhere except at the origin.\n\nWhat do we need the positivity for? As we have already mentioned, our main tool will be the minimization\nof quadratic functions. It would be nice to be sure that the minimum exists! For example, the function f (x) =\n−x^2 clearly has no minimum, because the number -1 is not positive, both branches of the parabola f (x)\nlook down. Positive definite matrices guarantee that the corresponding quadratic forms form a paraboloid\nwith a (unique) minimum. \n"},{"idx":71,"label":"28","overlay":1,"note":"Allow me to ask a very stupid question: what is a positive number? We have a great tool called the predicate\n“greater than” >. Do not be in a hurry to answer that the number a is positive if and only if a > 0, it would\nbe too easy. Let us define the positivity as follows:\n\nThe real number a is positive if and only if for all non-zero real x ∈ R, x != 0 the condition ax^2 > 0 is satisfied.\n\nThis definition looks pretty awkward, but it applies perfectly to matrices:\n\nA square matrix A is called positive definite if for any non-zero x the condition x^t Ax > 0\nis met, i.e. the corresponding quadratic form is strictly positive everywhere except at the origin.\n\nWhat do we need the positivity for? As we have already mentioned, our main tool will be the minimization\nof quadratic functions. It would be nice to be sure that the minimum exists! For example, the function f (x) =\n−x^2 clearly has no minimum, because the number -1 is not positive, both branches of the parabola f (x)\nlook down. Positive definite matrices guarantee that the corresponding quadratic forms form a paraboloid\nwith a (unique) minimum. \n"},{"idx":72,"label":"28","overlay":2,"note":"Allow me to ask a very stupid question: what is a positive number? We have a great tool called the predicate\n“greater than” >. Do not be in a hurry to answer that the number a is positive if and only if a > 0, it would\nbe too easy. Let us define the positivity as follows:\n\nThe real number a is positive if and only if for all non-zero real x ∈ R, x != 0 the condition ax^2 > 0 is satisfied.\n\nThis definition looks pretty awkward, but it applies perfectly to matrices:\n\nA square matrix A is called positive definite if for any non-zero x the condition x^t Ax > 0\nis met, i.e. the corresponding quadratic form is strictly positive everywhere except at the origin.\n\nWhat do we need the positivity for? As we have already mentioned, our main tool will be the minimization\nof quadratic functions. It would be nice to be sure that the minimum exists! For example, the function f (x) =\n−x^2 clearly has no minimum, because the number -1 is not positive, both branches of the parabola f (x)\nlook down. Positive definite matrices guarantee that the corresponding quadratic forms form a paraboloid\nwith a (unique) minimum. \n"},{"idx":73,"label":"29","overlay":0,"note":"Here is an illustration.\n\nThus, we will work with a generalization of positive numbers, namely, positive definite matrices. More-\nover, in our particular case, the matrices will be symmetric! Note that quite often, when people talk about\npositive definiteness, they also imply symmetry.\n"},{"idx":114,"label":"41","overlay":0,"note":"This section is the main part of the course. We will consider few different problems that can be solved with least squares. The idea is to show main turning knobs to allow you to instantiate least squares in different settings for your problems.\n"},{"idx":115,"label":"42","overlay":0,"note":"Let us start with a tiny example from the optimal control theory.\nOptimal control deals with the problem of finding a control law for a given system such that a certain optimality criterion is achieved.\nThis phrase is way too unspecific, let us illustrate it. Imagine that we have a car that advances with some speed, say 0.5m/s. The goal is to accelerate and reach, say, 2.3m/s. Here I sample the signals every 1 second, and I leave a half a minute to reach the given speed.\n\nWe can not control the speed directly, but we can act on the acceleration via the gas pedal. We can model the system with a very simple equation that tells us that the speed is equal to the initial speed v_0 plus the integral of the acceleration.\nRecall that I highlight unknown values in red, and known values in green.\n\nSo, our goal is to find a sequence of u that optimizes some quality criterion J that depends on the state of the system v and the control u.\n\nThe case where the system dynamics is described by a set of linear differential equations and the cost J is described by a quadratic functional is called a linear quadratic problem.\n\nLet us test few different quality criteria for the same problem.\n\nFor example, what happens if we ask for the car to reach the final speed as quickly as possible? It can be written as follows. We penalize the deviation of the velocity v_i from the goal v_n, and here I have just expanded the expression v_i.\n"},{"idx":116,"label":"42","overlay":1,"note":"Let us start with a tiny example from the optimal control theory.\nOptimal control deals with the problem of finding a control law for a given system such that a certain optimality criterion is achieved.\nThis phrase is way too unspecific, let us illustrate it. Imagine that we have a car that advances with some speed, say 0.5m/s. The goal is to accelerate and reach, say, 2.3m/s. Here I sample the signals every 1 second, and I leave a half a minute to reach the given speed.\n\nWe can not control the speed directly, but we can act on the acceleration via the gas pedal. We can model the system with a very simple equation that tells us that the speed is equal to the initial speed v_0 plus the integral of the acceleration.\nRecall that I highlight unknown values in red, and known values in green.\n\nSo, our goal is to find a sequence of u that optimizes some quality criterion J that depends on the state of the system v and the control u.\n\nThe case where the system dynamics is described by a set of linear differential equations and the cost J is described by a quadratic functional is called a linear quadratic problem.\n\nLet us test few different quality criteria for the same problem.\n\nFor example, what happens if we ask for the car to reach the final speed as quickly as possible? It can be written as follows. We penalize the deviation of the velocity v_i from the goal v_n, and here I have just expanded the expression v_i.\n"},{"idx":117,"label":"42","overlay":2,"note":"Let us start with a tiny example from the optimal control theory.\nOptimal control deals with the problem of finding a control law for a given system such that a certain optimality criterion is achieved.\nThis phrase is way too unspecific, let us illustrate it. Imagine that we have a car that advances with some speed, say 0.5m/s. The goal is to accelerate and reach, say, 2.3m/s. Here I sample the signals every 1 second, and I leave a half a minute to reach the given speed.\n\nWe can not control the speed directly, but we can act on the acceleration via the gas pedal. We can model the system with a very simple equation that tells us that the speed is equal to the initial speed v_0 plus the integral of the acceleration.\nRecall that I highlight unknown values in red, and known values in green.\n\nSo, our goal is to find a sequence of u that optimizes some quality criterion J that depends on the state of the system v and the control u.\n\nThe case where the system dynamics is described by a set of linear differential equations and the cost J is described by a quadratic functional is called a linear quadratic problem.\n\nLet us test few different quality criteria for the same problem.\n\nFor example, what happens if we ask for the car to reach the final speed as quickly as possible? It can be written as follows. We penalize the deviation of the velocity v_i from the goal v_n, and here I have just expanded the expression v_i.\n"},{"idx":118,"label":"43","overlay":0,"note":"To minimize this criterion, we can solve the following system in the least squares sense. In this particular case the system is not overdetermined, so it is easy to see that we have the solution u_0 = v_n - v_0, and the rest of u_i is equal to zero.\nThis obviously results in a quite brutal acceleration well beyond of physical capabilities of our car.\n"},{"idx":119,"label":"43","overlay":1,"note":"To minimize this criterion, we can solve the following system in the least squares sense. In this particular case the system is not overdetermined, so it is easy to see that we have the solution u_0 = v_n - v_0, and the rest of u_i is equal to zero.\nThis obviously results in a quite brutal acceleration well beyond of physical capabilities of our car.\n"},{"idx":120,"label":"44","overlay":0,"note":"So, how to cope with the problem? Let us try another quality criterion that penalizes large accelerations. Here we say that at every moment we want the acceleration to be as low as possible by taking a sum of u_i squared, and in addition to that, I put a constraint to the system that forces the car to reach the goal speed after the half a minute.\nThis sum is the final speed for the car, and I want it to be close to the v_n.\n\nHere is a piece of Python code that solves the system.\nSo, we start by building a system matrix A and we stack an identity matrix with a last row filled by ones.\nThe right hand side is a stack of a zero vector with vn-v0 appended to the end.\nWe obtain the control signal u by solving the system A transposed times A times u equal A transposed b, and in the final line we reconstruct the velocities from the control signal that we have just computed.\n\nHere is a plot of the solution. Indeed, the acceleration is very low, however, the transient time is unacceptable: we can not leave the car to take 30 seconds to accelerate to 2.3 m/s.\n\nMinimization of the transient time and low acceleration are competing goals, but we can find a trade-off by mixing both goals.\n"},{"idx":121,"label":"44","overlay":1,"note":"So, how to cope with the problem? Let us try another quality criterion that penalizes large accelerations. Here we say that at every moment we want the acceleration to be as low as possible by taking a sum of u_i squared, and in addition to that, I put a constraint to the system that forces the car to reach the goal speed after the half a minute.\nThis sum is the final speed for the car, and I want it to be close to the v_n.\n\nHere is a piece of Python code that solves the system.\nSo, we start by building a system matrix A and we stack an identity matrix with a last row filled by ones.\nThe right hand side is a stack of a zero vector with vn-v0 appended to the end.\nWe obtain the control signal u by solving the system A transposed times A times u equal A transposed b, and in the final line we reconstruct the velocities from the control signal that we have just computed.\n\nHere is a plot of the solution. Indeed, the acceleration is very low, however, the transient time is unacceptable: we can not leave the car to take 30 seconds to accelerate to 2.3 m/s.\n\nMinimization of the transient time and low acceleration are competing goals, but we can find a trade-off by mixing both goals.\n"},{"idx":122,"label":"44","overlay":2,"note":"So, how to cope with the problem? Let us try another quality criterion that penalizes large accelerations. Here we say that at every moment we want the acceleration to be as low as possible by taking a sum of u_i squared, and in addition to that, I put a constraint to the system that forces the car to reach the goal speed after the half a minute.\nThis sum is the final speed for the car, and I want it to be close to the v_n.\n\nHere is a piece of Python code that solves the system.\nSo, we start by building a system matrix A and we stack an identity matrix with a last row filled by ones.\nThe right hand side is a stack of a zero vector with vn-v0 appended to the end.\nWe obtain the control signal u by solving the system A transposed times A times u equal A transposed b, and in the final line we reconstruct the velocities from the control signal that we have just computed.\n\nHere is a plot of the solution. Indeed, the acceleration is very low, however, the transient time is unacceptable: we can not leave the car to take 30 seconds to accelerate to 2.3 m/s.\n\nMinimization of the transient time and low acceleration are competing goals, but we can find a trade-off by mixing both goals.\n"},{"idx":123,"label":"45","overlay":0,"note":"Let us try a third criterion asks to reach the goal as quickly as possible, while penalizing large accelerations.\n\nIt can be minimized by solving the following system.\nNote the coefficient 2 (or 4 when squared) in the equations and recall that we solve the system in the least squares sense.\nBy changing this coefficient, we can attach more importance to one of the competing goals.\nFollowing listing solves this system.\nAgain, the system matrix A is build from a stack of a lower triangular matrix of ones, and a diagonal matrix with 2 at its main diagonal.\nThe right hand side is a stack of two vectors prescribing the competing goals.\n\nAnd here is a plot of the solution, and it looks like a reasonable behaviour for a car.\nIn practice, just like we did in this section, engineers try different combinations of competing goals until they\nobtain a satisfactory transient time while not exceeding regulation capabilities.\n\n"},{"idx":124,"label":"45","overlay":1,"note":"Let us try a third criterion asks to reach the goal as quickly as possible, while penalizing large accelerations.\n\nIt can be minimized by solving the following system.\nNote the coefficient 2 (or 4 when squared) in the equations and recall that we solve the system in the least squares sense.\nBy changing this coefficient, we can attach more importance to one of the competing goals.\nFollowing listing solves this system.\nAgain, the system matrix A is build from a stack of a lower triangular matrix of ones, and a diagonal matrix with 2 at its main diagonal.\nThe right hand side is a stack of two vectors prescribing the competing goals.\n\nAnd here is a plot of the solution, and it looks like a reasonable behaviour for a car.\nIn practice, just like we did in this section, engineers try different combinations of competing goals until they\nobtain a satisfactory transient time while not exceeding regulation capabilities.\n\n"},{"idx":125,"label":"45","overlay":2,"note":"Let us try a third criterion asks to reach the goal as quickly as possible, while penalizing large accelerations.\n\nIt can be minimized by solving the following system.\nNote the coefficient 2 (or 4 when squared) in the equations and recall that we solve the system in the least squares sense.\nBy changing this coefficient, we can attach more importance to one of the competing goals.\nFollowing listing solves this system.\nAgain, the system matrix A is build from a stack of a lower triangular matrix of ones, and a diagonal matrix with 2 at its main diagonal.\nThe right hand side is a stack of two vectors prescribing the competing goals.\n\nAnd here is a plot of the solution, and it looks like a reasonable behaviour for a car.\nIn practice, just like we did in this section, engineers try different combinations of competing goals until they\nobtain a satisfactory transient time while not exceeding regulation capabilities.\n\n"},{"idx":126,"label":"45","overlay":3,"note":"Let us try a third criterion asks to reach the goal as quickly as possible, while penalizing large accelerations.\n\nIt can be minimized by solving the following system.\nNote the coefficient 2 (or 4 when squared) in the equations and recall that we solve the system in the least squares sense.\nBy changing this coefficient, we can attach more importance to one of the competing goals.\nFollowing listing solves this system.\nAgain, the system matrix A is build from a stack of a lower triangular matrix of ones, and a diagonal matrix with 2 at its main diagonal.\nThe right hand side is a stack of two vectors prescribing the competing goals.\n\nAnd here is a plot of the solution, and it looks like a reasonable behaviour for a car.\nIn practice, just like we did in this section, engineers try different combinations of competing goals until they\nobtain a satisfactory transient time while not exceeding regulation capabilities.\n\n"},{"idx":127,"label":"45","overlay":4,"note":"Let us try a third criterion asks to reach the goal as quickly as possible, while penalizing large accelerations.\n\nIt can be minimized by solving the following system.\nNote the coefficient 2 (or 4 when squared) in the equations and recall that we solve the system in the least squares sense.\nBy changing this coefficient, we can attach more importance to one of the competing goals.\nFollowing listing solves this system.\nAgain, the system matrix A is build from a stack of a lower triangular matrix of ones, and a diagonal matrix with 2 at its main diagonal.\nThe right hand side is a stack of two vectors prescribing the competing goals.\n\nAnd here is a plot of the solution, and it looks like a reasonable behaviour for a car.\nIn practice, just like we did in this section, engineers try different combinations of competing goals until they\nobtain a satisfactory transient time while not exceeding regulation capabilities.\n\n"},{"idx":128,"label":"46","overlay":0,"note":"So, the takeaway message is that for the same problem, the same choice of variables, tweaking the objective function produces very different results.\nUse it to your advantage!\n"},{"idx":129,"label":"47","overlay":0,"note":"Now let us move way closer to computer graphics. Poisson's equation is widely used for example, in image editing that we will see shortly.\nBut first let us start with the 1D basics.\nSo, the problem is to find an unknown function f(x) defined over some interval that ressembles an input function g subject to boundary constraints.\nRecall that I highlight unknown values in red, and known values in green.\n\nWe can formulate the problem as find f whose second derivative is equal to the second derivative of g with boundary fixed.\nThe easiest way to solve the problem is to use a neanderthal smoothing method that was very common a couple of decades ago.\n\nSo I sample the function with 32 values, I precompute the samples for the function g,\nI initialize the function f as the boundary values plus the zero function for the interior, and I smooth the function just as we have made a number of times before.\nMore specifically, I prescribe the second order finite difference over f to be equal to the second order difference over g by Gauss-Seidel iterations.\n\nThis approach is very simple to implement, however quite hard to tweak.\nLet us consider the same thing from a different perspective, I want to reformulate the problem as a minimization.\n"},{"idx":130,"label":"47","overlay":1,"note":"Now let us move way closer to computer graphics. Poisson's equation is widely used for example, in image editing that we will see shortly.\nBut first let us start with the 1D basics.\nSo, the problem is to find an unknown function f(x) defined over some interval that ressembles an input function g subject to boundary constraints.\nRecall that I highlight unknown values in red, and known values in green.\n\nWe can formulate the problem as find f whose second derivative is equal to the second derivative of g with boundary fixed.\nThe easiest way to solve the problem is to use a neanderthal smoothing method that was very common a couple of decades ago.\n\nSo I sample the function with 32 values, I precompute the samples for the function g,\nI initialize the function f as the boundary values plus the zero function for the interior, and I smooth the function just as we have made a number of times before.\nMore specifically, I prescribe the second order finite difference over f to be equal to the second order difference over g by Gauss-Seidel iterations.\n\nThis approach is very simple to implement, however quite hard to tweak.\nLet us consider the same thing from a different perspective, I want to reformulate the problem as a minimization.\n"},{"idx":131,"label":"48","overlay":0,"note":"Note that solving Laplace's equation \\Delta f=0, subject to appropriate boundary conditions,\nis equivalent to solving the variational problem of finding a function f that satisfies the boundary conditions and has minimal Dirichlet energy.\nIndeed, application of Euler-Lagrange equations for the minimization problem results in the Laplace's equation.\n\nSame goes for Poisson's equation.\nSolving \\Delta f = g is equivalent to minimizing the integral of the squared norm of gradient f minus gradient g.\n\nTurns out it is a quadratic energy to minimize and we know just a method to do this very efficiently!\nThus, after a discretization, we need to solve the following system in the least squares sense.\nHere I simply want the first order finite differences of f and g coincide.\n\nHere is a short Python code that solves the system.\nAs before, we have 33 samples, we precompute the function g,\nwe fill the matrix A with two diagonals built from ones and minus ones, respectively, and we compute the right hand side vector b.\n\nThen we solve for A transposed times A times f equals A transposed times b and we get the solution.\n"},{"idx":132,"label":"48","overlay":1,"note":"Note that solving Laplace's equation \\Delta f=0, subject to appropriate boundary conditions,\nis equivalent to solving the variational problem of finding a function f that satisfies the boundary conditions and has minimal Dirichlet energy.\nIndeed, application of Euler-Lagrange equations for the minimization problem results in the Laplace's equation.\n\nSame goes for Poisson's equation.\nSolving \\Delta f = g is equivalent to minimizing the integral of the squared norm of gradient f minus gradient g.\n\nTurns out it is a quadratic energy to minimize and we know just a method to do this very efficiently!\nThus, after a discretization, we need to solve the following system in the least squares sense.\nHere I simply want the first order finite differences of f and g coincide.\n\nHere is a short Python code that solves the system.\nAs before, we have 33 samples, we precompute the function g,\nwe fill the matrix A with two diagonals built from ones and minus ones, respectively, and we compute the right hand side vector b.\n\nThen we solve for A transposed times A times f equals A transposed times b and we get the solution.\n"},{"idx":133,"label":"48","overlay":2,"note":"Note that solving Laplace's equation \\Delta f=0, subject to appropriate boundary conditions,\nis equivalent to solving the variational problem of finding a function f that satisfies the boundary conditions and has minimal Dirichlet energy.\nIndeed, application of Euler-Lagrange equations for the minimization problem results in the Laplace's equation.\n\nSame goes for Poisson's equation.\nSolving \\Delta f = g is equivalent to minimizing the integral of the squared norm of gradient f minus gradient g.\n\nTurns out it is a quadratic energy to minimize and we know just a method to do this very efficiently!\nThus, after a discretization, we need to solve the following system in the least squares sense.\nHere I simply want the first order finite differences of f and g coincide.\n\nHere is a short Python code that solves the system.\nAs before, we have 33 samples, we precompute the function g,\nwe fill the matrix A with two diagonals built from ones and minus ones, respectively, and we compute the right hand side vector b.\n\nThen we solve for A transposed times A times f equals A transposed times b and we get the solution.\n"},{"idx":134,"label":"49","overlay":0,"note":"Now we are ready for a simple image editing example.\nI want to replace the baseball from the left image with the football. A direct overlay leads to a unsatisfactory result as can be seen in the right image.\nHow to swap the content seamlessly?\nPoisson’s equation can be of help here, we can do better.\nAll color channels are solved independently one from another, so we can say that we manipulate grayscale images.\n\nLet us say that we have two real-valued functions (a) (sub-image of the baseball photo) and (b) (the football image) defined over \\Omega.\nHere for the sake of simplicity we consider a rectangular domain \\Omega.\nSo, we are looking for the function f that takes its boundary conditions from a and the gradients from b.\n"},{"idx":135,"label":"49","overlay":1,"note":"Now we are ready for a simple image editing example.\nI want to replace the baseball from the left image with the football. A direct overlay leads to a unsatisfactory result as can be seen in the right image.\nHow to swap the content seamlessly?\nPoisson’s equation can be of help here, we can do better.\nAll color channels are solved independently one from another, so we can say that we manipulate grayscale images.\n\nLet us say that we have two real-valued functions (a) (sub-image of the baseball photo) and (b) (the football image) defined over \\Omega.\nHere for the sake of simplicity we consider a rectangular domain \\Omega.\nSo, we are looking for the function f that takes its boundary conditions from a and the gradients from b.\n"},{"idx":136,"label":"49","overlay":2,"note":"Now we are ready for a simple image editing example.\nI want to replace the baseball from the left image with the football. A direct overlay leads to a unsatisfactory result as can be seen in the right image.\nHow to swap the content seamlessly?\nPoisson’s equation can be of help here, we can do better.\nAll color channels are solved independently one from another, so we can say that we manipulate grayscale images.\n\nLet us say that we have two real-valued functions (a) (sub-image of the baseball photo) and (b) (the football image) defined over \\Omega.\nHere for the sake of simplicity we consider a rectangular domain \\Omega.\nSo, we are looking for the function f that takes its boundary conditions from a and the gradients from b.\n"},{"idx":137,"label":"49","overlay":3,"note":"Now we are ready for a simple image editing example.\nI want to replace the baseball from the left image with the football. A direct overlay leads to a unsatisfactory result as can be seen in the right image.\nHow to swap the content seamlessly?\nPoisson’s equation can be of help here, we can do better.\nAll color channels are solved independently one from another, so we can say that we manipulate grayscale images.\n\nLet us say that we have two real-valued functions (a) (sub-image of the baseball photo) and (b) (the football image) defined over \\Omega.\nHere for the sake of simplicity we consider a rectangular domain \\Omega.\nSo, we are looking for the function f that takes its boundary conditions from a and the gradients from b.\n"},{"idx":138,"label":"49","overlay":4,"note":"Now we are ready for a simple image editing example.\nI want to replace the baseball from the left image with the football. A direct overlay leads to a unsatisfactory result as can be seen in the right image.\nHow to swap the content seamlessly?\nPoisson’s equation can be of help here, we can do better.\nAll color channels are solved independently one from another, so we can say that we manipulate grayscale images.\n\nLet us say that we have two real-valued functions (a) (sub-image of the baseball photo) and (b) (the football image) defined over \\Omega.\nHere for the sake of simplicity we consider a rectangular domain \\Omega.\nSo, we are looking for the function f that takes its boundary conditions from a and the gradients from b.\n"},{"idx":139,"label":"50","overlay":0,"note":"We can discretize the problem exactly as in the previous example: we have w x h-pixels grayscale images a and b.\nTo compute a w x h-pixels image f, we can solve the following system in the least squares sense.\n\n\nNote that if we solve for an image that is 1000 pixels wide and 1000 pixels tall, we have one million unknowns, and thus the matrix A transposed times A is one million by one million.\nFortunately, it is sparse: it contains only few non-zero entries at each row, so the problem is still tractable.\n\nYou can find the source code at the github repository, and here you can see the result.\nWhile it is not completely perfect, we can still trace the rectangle boundary, it is, however, much better than the direct overlay for a very  humble cost.\n"},{"idx":140,"label":"50","overlay":1,"note":"We can discretize the problem exactly as in the previous example: we have w x h-pixels grayscale images a and b.\nTo compute a w x h-pixels image f, we can solve the following system in the least squares sense.\n\n\nNote that if we solve for an image that is 1000 pixels wide and 1000 pixels tall, we have one million unknowns, and thus the matrix A transposed times A is one million by one million.\nFortunately, it is sparse: it contains only few non-zero entries at each row, so the problem is still tractable.\n\nYou can find the source code at the github repository, and here you can see the result.\nWhile it is not completely perfect, we can still trace the rectangle boundary, it is, however, much better than the direct overlay for a very  humble cost.\n"},{"idx":141,"label":"50","overlay":2,"note":"We can discretize the problem exactly as in the previous example: we have w x h-pixels grayscale images a and b.\nTo compute a w x h-pixels image f, we can solve the following system in the least squares sense.\n\n\nNote that if we solve for an image that is 1000 pixels wide and 1000 pixels tall, we have one million unknowns, and thus the matrix A transposed times A is one million by one million.\nFortunately, it is sparse: it contains only few non-zero entries at each row, so the problem is still tractable.\n\nYou can find the source code at the github repository, and here you can see the result.\nWhile it is not completely perfect, we can still trace the rectangle boundary, it is, however, much better than the direct overlay for a very  humble cost.\n"},{"idx":142,"label":"51","overlay":0,"note":"The takeaway message here is that thanks to their simplicity and their power, Laplace's and Poisson's problems are widely used tools in geometry and image processing, and it is very handy to know your friends.\n"},{"idx":143,"label":"52","overlay":0,"note":"Let us move on to the next example. I want to create goofy portraits.\nCaricature, a type of exaggerated artistic portrait, amplifies the characteristic traits of human faces.\nTypically, this task is left to artists, as it was proven difficult for automated methods.\nHere I show an extremely naive approach, starting with a 2D silhouette.\nThis section is closely related to Poisson image editing described in the previous example.\n\nLet us consider the following Python program:\nIt defines a 2D silhouette as a closed polyline represented by two same length arrays x and y.\n\nThe idea is to increase the curvature of the polyline, thus exaggerating the traits.\nTo this end, we compute the curvatures via finite differences and store it in the arrays cx and cy.\nThen we want to solve the Poisson's equation with the increased curvature as the right hand side of the equation.\nSo, we perform a number of Gauß-Seidel iterations to solve the equation.\nAt the bottom of the slide we can see the evolution of the polyline.\nAfter 10 iterations the drawing looks very good, exactly what we had in mind, but what happens next?\nWell, there is no surprise: in the end we obtain an inflated version of the input, because it corresponds exactly to what we have asked for.\nTo scale finite differences is the same as to scale the input signal...\nHow to fix it? Well, we can stop the process after 10 iterations,\nthus exploiting the fact that Gauß-Seidel has a slow convergence in low frequencies, but it is a unsatisfactory solution.\nIt would much be better if the result was at the true minimum of our optimization routine.\n\nAs before, let us rewrite the same problem as a minimization, it will allow us to tweak the energy.\nThe listing we have just saw corresponds to the following optimization problem to be solved independently for x and y coordinates.\nHere x_i are the input coordinates and x'_i are the unknowns. Coefficient c corresponds to the scaling coefficient.\nThe problem is separable in two coordinates, so we list here only the x part.\n"},{"idx":144,"label":"52","overlay":1,"note":"Let us move on to the next example. I want to create goofy portraits.\nCaricature, a type of exaggerated artistic portrait, amplifies the characteristic traits of human faces.\nTypically, this task is left to artists, as it was proven difficult for automated methods.\nHere I show an extremely naive approach, starting with a 2D silhouette.\nThis section is closely related to Poisson image editing described in the previous example.\n\nLet us consider the following Python program:\nIt defines a 2D silhouette as a closed polyline represented by two same length arrays x and y.\n\nThe idea is to increase the curvature of the polyline, thus exaggerating the traits.\nTo this end, we compute the curvatures via finite differences and store it in the arrays cx and cy.\nThen we want to solve the Poisson's equation with the increased curvature as the right hand side of the equation.\nSo, we perform a number of Gauß-Seidel iterations to solve the equation.\nAt the bottom of the slide we can see the evolution of the polyline.\nAfter 10 iterations the drawing looks very good, exactly what we had in mind, but what happens next?\nWell, there is no surprise: in the end we obtain an inflated version of the input, because it corresponds exactly to what we have asked for.\nTo scale finite differences is the same as to scale the input signal...\nHow to fix it? Well, we can stop the process after 10 iterations,\nthus exploiting the fact that Gauß-Seidel has a slow convergence in low frequencies, but it is a unsatisfactory solution.\nIt would much be better if the result was at the true minimum of our optimization routine.\n\nAs before, let us rewrite the same problem as a minimization, it will allow us to tweak the energy.\nThe listing we have just saw corresponds to the following optimization problem to be solved independently for x and y coordinates.\nHere x_i are the input coordinates and x'_i are the unknowns. Coefficient c corresponds to the scaling coefficient.\nThe problem is separable in two coordinates, so we list here only the x part.\n"},{"idx":145,"label":"52","overlay":2,"note":"Let us move on to the next example. I want to create goofy portraits.\nCaricature, a type of exaggerated artistic portrait, amplifies the characteristic traits of human faces.\nTypically, this task is left to artists, as it was proven difficult for automated methods.\nHere I show an extremely naive approach, starting with a 2D silhouette.\nThis section is closely related to Poisson image editing described in the previous example.\n\nLet us consider the following Python program:\nIt defines a 2D silhouette as a closed polyline represented by two same length arrays x and y.\n\nThe idea is to increase the curvature of the polyline, thus exaggerating the traits.\nTo this end, we compute the curvatures via finite differences and store it in the arrays cx and cy.\nThen we want to solve the Poisson's equation with the increased curvature as the right hand side of the equation.\nSo, we perform a number of Gauß-Seidel iterations to solve the equation.\nAt the bottom of the slide we can see the evolution of the polyline.\nAfter 10 iterations the drawing looks very good, exactly what we had in mind, but what happens next?\nWell, there is no surprise: in the end we obtain an inflated version of the input, because it corresponds exactly to what we have asked for.\nTo scale finite differences is the same as to scale the input signal...\nHow to fix it? Well, we can stop the process after 10 iterations,\nthus exploiting the fact that Gauß-Seidel has a slow convergence in low frequencies, but it is a unsatisfactory solution.\nIt would much be better if the result was at the true minimum of our optimization routine.\n\nAs before, let us rewrite the same problem as a minimization, it will allow us to tweak the energy.\nThe listing we have just saw corresponds to the following optimization problem to be solved independently for x and y coordinates.\nHere x_i are the input coordinates and x'_i are the unknowns. Coefficient c corresponds to the scaling coefficient.\nThe problem is separable in two coordinates, so we list here only the x part.\n"},{"idx":146,"label":"52","overlay":3,"note":"Let us move on to the next example. I want to create goofy portraits.\nCaricature, a type of exaggerated artistic portrait, amplifies the characteristic traits of human faces.\nTypically, this task is left to artists, as it was proven difficult for automated methods.\nHere I show an extremely naive approach, starting with a 2D silhouette.\nThis section is closely related to Poisson image editing described in the previous example.\n\nLet us consider the following Python program:\nIt defines a 2D silhouette as a closed polyline represented by two same length arrays x and y.\n\nThe idea is to increase the curvature of the polyline, thus exaggerating the traits.\nTo this end, we compute the curvatures via finite differences and store it in the arrays cx and cy.\nThen we want to solve the Poisson's equation with the increased curvature as the right hand side of the equation.\nSo, we perform a number of Gauß-Seidel iterations to solve the equation.\nAt the bottom of the slide we can see the evolution of the polyline.\nAfter 10 iterations the drawing looks very good, exactly what we had in mind, but what happens next?\nWell, there is no surprise: in the end we obtain an inflated version of the input, because it corresponds exactly to what we have asked for.\nTo scale finite differences is the same as to scale the input signal...\nHow to fix it? Well, we can stop the process after 10 iterations,\nthus exploiting the fact that Gauß-Seidel has a slow convergence in low frequencies, but it is a unsatisfactory solution.\nIt would much be better if the result was at the true minimum of our optimization routine.\n\nAs before, let us rewrite the same problem as a minimization, it will allow us to tweak the energy.\nThe listing we have just saw corresponds to the following optimization problem to be solved independently for x and y coordinates.\nHere x_i are the input coordinates and x'_i are the unknowns. Coefficient c corresponds to the scaling coefficient.\nThe problem is separable in two coordinates, so we list here only the x part.\n"},{"idx":147,"label":"53","overlay":0,"note":"Having rewritten the problem as a minimization, we can fix it.\nThe simplest way to prevent the \"inflation\" of the model is to add a data attachment term.\nFirst we start with the energy term we have already written, and then add a second term.\nSo, basically we want to scale the gradient AND we want the deformation to be small.\nThe coefficients c0 and c1 allow us to tune the optimization to achieve the desired trade-off between the curvature exaggeration and the data attachment.\n\nTo minimize this energy, we can solve the following system in the least squares sense.\nAs usual, you can find the source code in the github repo, and here is what the result looks like.\nThe sweet part is that this formulation works out of the box for 3d surfaces as well!\n\nTo recapitulate, we took a basic Poisson's equation and then just added a light data fitting term to the energy.\nThe takeaway message here is that reformulating as a least squares problem allows for a much easier tweaking.\n"},{"idx":148,"label":"53","overlay":1,"note":"Having rewritten the problem as a minimization, we can fix it.\nThe simplest way to prevent the \"inflation\" of the model is to add a data attachment term.\nFirst we start with the energy term we have already written, and then add a second term.\nSo, basically we want to scale the gradient AND we want the deformation to be small.\nThe coefficients c0 and c1 allow us to tune the optimization to achieve the desired trade-off between the curvature exaggeration and the data attachment.\n\nTo minimize this energy, we can solve the following system in the least squares sense.\nAs usual, you can find the source code in the github repo, and here is what the result looks like.\nThe sweet part is that this formulation works out of the box for 3d surfaces as well!\n\nTo recapitulate, we took a basic Poisson's equation and then just added a light data fitting term to the energy.\nThe takeaway message here is that reformulating as a least squares problem allows for a much easier tweaking.\n"},{"idx":149,"label":"53","overlay":2,"note":"Having rewritten the problem as a minimization, we can fix it.\nThe simplest way to prevent the \"inflation\" of the model is to add a data attachment term.\nFirst we start with the energy term we have already written, and then add a second term.\nSo, basically we want to scale the gradient AND we want the deformation to be small.\nThe coefficients c0 and c1 allow us to tune the optimization to achieve the desired trade-off between the curvature exaggeration and the data attachment.\n\nTo minimize this energy, we can solve the following system in the least squares sense.\nAs usual, you can find the source code in the github repo, and here is what the result looks like.\nThe sweet part is that this formulation works out of the box for 3d surfaces as well!\n\nTo recapitulate, we took a basic Poisson's equation and then just added a light data fitting term to the energy.\nThe takeaway message here is that reformulating as a least squares problem allows for a much easier tweaking.\n"},{"idx":150,"label":"53","overlay":3,"note":"Having rewritten the problem as a minimization, we can fix it.\nThe simplest way to prevent the \"inflation\" of the model is to add a data attachment term.\nFirst we start with the energy term we have already written, and then add a second term.\nSo, basically we want to scale the gradient AND we want the deformation to be small.\nThe coefficients c0 and c1 allow us to tune the optimization to achieve the desired trade-off between the curvature exaggeration and the data attachment.\n\nTo minimize this energy, we can solve the following system in the least squares sense.\nAs usual, you can find the source code in the github repo, and here is what the result looks like.\nThe sweet part is that this formulation works out of the box for 3d surfaces as well!\n\nTo recapitulate, we took a basic Poisson's equation and then just added a light data fitting term to the energy.\nThe takeaway message here is that reformulating as a least squares problem allows for a much easier tweaking.\n"},{"idx":151,"label":"53","overlay":4,"note":"Having rewritten the problem as a minimization, we can fix it.\nThe simplest way to prevent the \"inflation\" of the model is to add a data attachment term.\nFirst we start with the energy term we have already written, and then add a second term.\nSo, basically we want to scale the gradient AND we want the deformation to be small.\nThe coefficients c0 and c1 allow us to tune the optimization to achieve the desired trade-off between the curvature exaggeration and the data attachment.\n\nTo minimize this energy, we can solve the following system in the least squares sense.\nAs usual, you can find the source code in the github repo, and here is what the result looks like.\nThe sweet part is that this formulation works out of the box for 3d surfaces as well!\n\nTo recapitulate, we took a basic Poisson's equation and then just added a light data fitting term to the energy.\nThe takeaway message here is that reformulating as a least squares problem allows for a much easier tweaking.\n"},{"idx":152,"label":"53","overlay":5,"note":"Having rewritten the problem as a minimization, we can fix it.\nThe simplest way to prevent the \"inflation\" of the model is to add a data attachment term.\nFirst we start with the energy term we have already written, and then add a second term.\nSo, basically we want to scale the gradient AND we want the deformation to be small.\nThe coefficients c0 and c1 allow us to tune the optimization to achieve the desired trade-off between the curvature exaggeration and the data attachment.\n\nTo minimize this energy, we can solve the following system in the least squares sense.\nAs usual, you can find the source code in the github repo, and here is what the result looks like.\nThe sweet part is that this formulation works out of the box for 3d surfaces as well!\n\nTo recapitulate, we took a basic Poisson's equation and then just added a light data fitting term to the energy.\nThe takeaway message here is that reformulating as a least squares problem allows for a much easier tweaking.\n"},{"idx":153,"label":"53","overlay":6,"note":"Having rewritten the problem as a minimization, we can fix it.\nThe simplest way to prevent the \"inflation\" of the model is to add a data attachment term.\nFirst we start with the energy term we have already written, and then add a second term.\nSo, basically we want to scale the gradient AND we want the deformation to be small.\nThe coefficients c0 and c1 allow us to tune the optimization to achieve the desired trade-off between the curvature exaggeration and the data attachment.\n\nTo minimize this energy, we can solve the following system in the least squares sense.\nAs usual, you can find the source code in the github repo, and here is what the result looks like.\nThe sweet part is that this formulation works out of the box for 3d surfaces as well!\n\nTo recapitulate, we took a basic Poisson's equation and then just added a light data fitting term to the energy.\nThe takeaway message here is that reformulating as a least squares problem allows for a much easier tweaking.\n"},{"idx":154,"label":"53","overlay":7,"note":"Having rewritten the problem as a minimization, we can fix it.\nThe simplest way to prevent the \"inflation\" of the model is to add a data attachment term.\nFirst we start with the energy term we have already written, and then add a second term.\nSo, basically we want to scale the gradient AND we want the deformation to be small.\nThe coefficients c0 and c1 allow us to tune the optimization to achieve the desired trade-off between the curvature exaggeration and the data attachment.\n\nTo minimize this energy, we can solve the following system in the least squares sense.\nAs usual, you can find the source code in the github repo, and here is what the result looks like.\nThe sweet part is that this formulation works out of the box for 3d surfaces as well!\n\nTo recapitulate, we took a basic Poisson's equation and then just added a light data fitting term to the energy.\nThe takeaway message here is that reformulating as a least squares problem allows for a much easier tweaking.\n"},{"idx":155,"label":"54","overlay":0,"note":"Three more examples to go.\nLet us compute another deformation of a 3D surface, I want to cubify it.\nThe idea is to deform the surface by aligning triangles with one of the global coordinate planes, thus obtaining a moai statue effect.\n\nFirst of all for each triangle we compute the coordinate axis closest to its normal, and denote it as a_ijk.\nGiven a triangle with the normal vector N_ijk, we test three coordinate vectors and take the one with the largest dot product.\nSo we basically snap the normal to the closest coordinate axis.\n\nThree different colors (blue, white, pink) in the image correspond to the axes.\nAnd then we want to deform the surface according to this coloring. It is very easy to do.\nMy variables are still the coordinates of the mesh vertices, and for the simplicity of notations,\nI call by e_ij the vector corresponding to the edge (i, j) in the input data,\nand e'ij be the modified geometry (recall that I highlight the unknowns in red).\n\nHere is a quick test: what would be the result of the following optimization?\nWithout any doubt you have recognized the Poisson problem.\nWe have asked for the output edges to be as close as possible to the input edges, and it is perfectly feasible,\nso our deformation is an identity.\n\nWe will add few more terms to this energy to obtain the desired effect.\n\nTo do so, we can define the projection operator that takes a plane defined by its normal a and projects a vector v to this plane.\nThen the desired geometry can be obtained by minimizing the following energy.\n\nFor each triangle ijk we add a term pulls the triangle to be aligned with the chosen coordinate plane.\nMore specifically, for each edge we penalize the deviation of the output geometry from coplanarity with the plane defined by the axis a_ijk.\n\nNote the coefficient c representing the trade-off between the flattening force and the attachment to the old data.\nAs always, the source code is available.\n\nThe takeaway message here is that despite the same choice of variables as in the caricature example,\nwe have completely different results thanks to a different tweaking.\nWe explain to the solver what we want to get, and it is up to the solver to find the result.\n"},{"idx":156,"label":"54","overlay":1,"note":"Three more examples to go.\nLet us compute another deformation of a 3D surface, I want to cubify it.\nThe idea is to deform the surface by aligning triangles with one of the global coordinate planes, thus obtaining a moai statue effect.\n\nFirst of all for each triangle we compute the coordinate axis closest to its normal, and denote it as a_ijk.\nGiven a triangle with the normal vector N_ijk, we test three coordinate vectors and take the one with the largest dot product.\nSo we basically snap the normal to the closest coordinate axis.\n\nThree different colors (blue, white, pink) in the image correspond to the axes.\nAnd then we want to deform the surface according to this coloring. It is very easy to do.\nMy variables are still the coordinates of the mesh vertices, and for the simplicity of notations,\nI call by e_ij the vector corresponding to the edge (i, j) in the input data,\nand e'ij be the modified geometry (recall that I highlight the unknowns in red).\n\nHere is a quick test: what would be the result of the following optimization?\nWithout any doubt you have recognized the Poisson problem.\nWe have asked for the output edges to be as close as possible to the input edges, and it is perfectly feasible,\nso our deformation is an identity.\n\nWe will add few more terms to this energy to obtain the desired effect.\n\nTo do so, we can define the projection operator that takes a plane defined by its normal a and projects a vector v to this plane.\nThen the desired geometry can be obtained by minimizing the following energy.\n\nFor each triangle ijk we add a term pulls the triangle to be aligned with the chosen coordinate plane.\nMore specifically, for each edge we penalize the deviation of the output geometry from coplanarity with the plane defined by the axis a_ijk.\n\nNote the coefficient c representing the trade-off between the flattening force and the attachment to the old data.\nAs always, the source code is available.\n\nThe takeaway message here is that despite the same choice of variables as in the caricature example,\nwe have completely different results thanks to a different tweaking.\nWe explain to the solver what we want to get, and it is up to the solver to find the result.\n"},{"idx":157,"label":"54","overlay":2,"note":"Three more examples to go.\nLet us compute another deformation of a 3D surface, I want to cubify it.\nThe idea is to deform the surface by aligning triangles with one of the global coordinate planes, thus obtaining a moai statue effect.\n\nFirst of all for each triangle we compute the coordinate axis closest to its normal, and denote it as a_ijk.\nGiven a triangle with the normal vector N_ijk, we test three coordinate vectors and take the one with the largest dot product.\nSo we basically snap the normal to the closest coordinate axis.\n\nThree different colors (blue, white, pink) in the image correspond to the axes.\nAnd then we want to deform the surface according to this coloring. It is very easy to do.\nMy variables are still the coordinates of the mesh vertices, and for the simplicity of notations,\nI call by e_ij the vector corresponding to the edge (i, j) in the input data,\nand e'ij be the modified geometry (recall that I highlight the unknowns in red).\n\nHere is a quick test: what would be the result of the following optimization?\nWithout any doubt you have recognized the Poisson problem.\nWe have asked for the output edges to be as close as possible to the input edges, and it is perfectly feasible,\nso our deformation is an identity.\n\nWe will add few more terms to this energy to obtain the desired effect.\n\nTo do so, we can define the projection operator that takes a plane defined by its normal a and projects a vector v to this plane.\nThen the desired geometry can be obtained by minimizing the following energy.\n\nFor each triangle ijk we add a term pulls the triangle to be aligned with the chosen coordinate plane.\nMore specifically, for each edge we penalize the deviation of the output geometry from coplanarity with the plane defined by the axis a_ijk.\n\nNote the coefficient c representing the trade-off between the flattening force and the attachment to the old data.\nAs always, the source code is available.\n\nThe takeaway message here is that despite the same choice of variables as in the caricature example,\nwe have completely different results thanks to a different tweaking.\nWe explain to the solver what we want to get, and it is up to the solver to find the result.\n"},{"idx":158,"label":"54","overlay":3,"note":"Three more examples to go.\nLet us compute another deformation of a 3D surface, I want to cubify it.\nThe idea is to deform the surface by aligning triangles with one of the global coordinate planes, thus obtaining a moai statue effect.\n\nFirst of all for each triangle we compute the coordinate axis closest to its normal, and denote it as a_ijk.\nGiven a triangle with the normal vector N_ijk, we test three coordinate vectors and take the one with the largest dot product.\nSo we basically snap the normal to the closest coordinate axis.\n\nThree different colors (blue, white, pink) in the image correspond to the axes.\nAnd then we want to deform the surface according to this coloring. It is very easy to do.\nMy variables are still the coordinates of the mesh vertices, and for the simplicity of notations,\nI call by e_ij the vector corresponding to the edge (i, j) in the input data,\nand e'ij be the modified geometry (recall that I highlight the unknowns in red).\n\nHere is a quick test: what would be the result of the following optimization?\nWithout any doubt you have recognized the Poisson problem.\nWe have asked for the output edges to be as close as possible to the input edges, and it is perfectly feasible,\nso our deformation is an identity.\n\nWe will add few more terms to this energy to obtain the desired effect.\n\nTo do so, we can define the projection operator that takes a plane defined by its normal a and projects a vector v to this plane.\nThen the desired geometry can be obtained by minimizing the following energy.\n\nFor each triangle ijk we add a term pulls the triangle to be aligned with the chosen coordinate plane.\nMore specifically, for each edge we penalize the deviation of the output geometry from coplanarity with the plane defined by the axis a_ijk.\n\nNote the coefficient c representing the trade-off between the flattening force and the attachment to the old data.\nAs always, the source code is available.\n\nThe takeaway message here is that despite the same choice of variables as in the caricature example,\nwe have completely different results thanks to a different tweaking.\nWe explain to the solver what we want to get, and it is up to the solver to find the result.\n"},{"idx":159,"label":"54","overlay":4,"note":"Three more examples to go.\nLet us compute another deformation of a 3D surface, I want to cubify it.\nThe idea is to deform the surface by aligning triangles with one of the global coordinate planes, thus obtaining a moai statue effect.\n\nFirst of all for each triangle we compute the coordinate axis closest to its normal, and denote it as a_ijk.\nGiven a triangle with the normal vector N_ijk, we test three coordinate vectors and take the one with the largest dot product.\nSo we basically snap the normal to the closest coordinate axis.\n\nThree different colors (blue, white, pink) in the image correspond to the axes.\nAnd then we want to deform the surface according to this coloring. It is very easy to do.\nMy variables are still the coordinates of the mesh vertices, and for the simplicity of notations,\nI call by e_ij the vector corresponding to the edge (i, j) in the input data,\nand e'ij be the modified geometry (recall that I highlight the unknowns in red).\n\nHere is a quick test: what would be the result of the following optimization?\nWithout any doubt you have recognized the Poisson problem.\nWe have asked for the output edges to be as close as possible to the input edges, and it is perfectly feasible,\nso our deformation is an identity.\n\nWe will add few more terms to this energy to obtain the desired effect.\n\nTo do so, we can define the projection operator that takes a plane defined by its normal a and projects a vector v to this plane.\nThen the desired geometry can be obtained by minimizing the following energy.\n\nFor each triangle ijk we add a term pulls the triangle to be aligned with the chosen coordinate plane.\nMore specifically, for each edge we penalize the deviation of the output geometry from coplanarity with the plane defined by the axis a_ijk.\n\nNote the coefficient c representing the trade-off between the flattening force and the attachment to the old data.\nAs always, the source code is available.\n\nThe takeaway message here is that despite the same choice of variables as in the caricature example,\nwe have completely different results thanks to a different tweaking.\nWe explain to the solver what we want to get, and it is up to the solver to find the result.\n"},{"idx":160,"label":"55","overlay":0,"note":"Two more examples to go.\nHow to deform a character in a plausible manner?\nUsually this task is done by artists expertly rigging 3D models.\nHowever simple deformation models can still produce satisfying deformations.\n\nSo, starting from an input mesh, we choose a subset of its vertices, we move them, we lock them, and we want the rest of the mesh to deform accordingly.\nHere both screenshots are taken with the same camera angle, but the constraints imposed on the mesh naturally rotate the model around the vertical axis,\nwhile the tail moves to the other side of the character.\n\nFormally, we have the same choice of variables, namely, coordinates of the mesh vertices, and\nour deformation will be controlled by a subset of vertices I on the surface which will forced to the position p_k.\n\nThe first requirement one might have is that the deformation must be smooth.\nSo the first idea is to best preserve the edges of the original surface as best as possible while satisfying the position constraints.\nThe new vertex positions x' are obtained be solving the least squares problem.\nOnce again, this is a simple Poisson problem.\n\nThe resulting deformation however does not look realistic at all: the surface is badly stretched near the\nconstraints and the our deformation model is unable to create the global rotation induced by the constraints.\n\n"},{"idx":161,"label":"55","overlay":1,"note":"Two more examples to go.\nHow to deform a character in a plausible manner?\nUsually this task is done by artists expertly rigging 3D models.\nHowever simple deformation models can still produce satisfying deformations.\n\nSo, starting from an input mesh, we choose a subset of its vertices, we move them, we lock them, and we want the rest of the mesh to deform accordingly.\nHere both screenshots are taken with the same camera angle, but the constraints imposed on the mesh naturally rotate the model around the vertical axis,\nwhile the tail moves to the other side of the character.\n\nFormally, we have the same choice of variables, namely, coordinates of the mesh vertices, and\nour deformation will be controlled by a subset of vertices I on the surface which will forced to the position p_k.\n\nThe first requirement one might have is that the deformation must be smooth.\nSo the first idea is to best preserve the edges of the original surface as best as possible while satisfying the position constraints.\nThe new vertex positions x' are obtained be solving the least squares problem.\nOnce again, this is a simple Poisson problem.\n\nThe resulting deformation however does not look realistic at all: the surface is badly stretched near the\nconstraints and the our deformation model is unable to create the global rotation induced by the constraints.\n\n"},{"idx":162,"label":"55","overlay":2,"note":"Two more examples to go.\nHow to deform a character in a plausible manner?\nUsually this task is done by artists expertly rigging 3D models.\nHowever simple deformation models can still produce satisfying deformations.\n\nSo, starting from an input mesh, we choose a subset of its vertices, we move them, we lock them, and we want the rest of the mesh to deform accordingly.\nHere both screenshots are taken with the same camera angle, but the constraints imposed on the mesh naturally rotate the model around the vertical axis,\nwhile the tail moves to the other side of the character.\n\nFormally, we have the same choice of variables, namely, coordinates of the mesh vertices, and\nour deformation will be controlled by a subset of vertices I on the surface which will forced to the position p_k.\n\nThe first requirement one might have is that the deformation must be smooth.\nSo the first idea is to best preserve the edges of the original surface as best as possible while satisfying the position constraints.\nThe new vertex positions x' are obtained be solving the least squares problem.\nOnce again, this is a simple Poisson problem.\n\nThe resulting deformation however does not look realistic at all: the surface is badly stretched near the\nconstraints and the our deformation model is unable to create the global rotation induced by the constraints.\n\n"},{"idx":163,"label":"55","overlay":3,"note":"Two more examples to go.\nHow to deform a character in a plausible manner?\nUsually this task is done by artists expertly rigging 3D models.\nHowever simple deformation models can still produce satisfying deformations.\n\nSo, starting from an input mesh, we choose a subset of its vertices, we move them, we lock them, and we want the rest of the mesh to deform accordingly.\nHere both screenshots are taken with the same camera angle, but the constraints imposed on the mesh naturally rotate the model around the vertical axis,\nwhile the tail moves to the other side of the character.\n\nFormally, we have the same choice of variables, namely, coordinates of the mesh vertices, and\nour deformation will be controlled by a subset of vertices I on the surface which will forced to the position p_k.\n\nThe first requirement one might have is that the deformation must be smooth.\nSo the first idea is to best preserve the edges of the original surface as best as possible while satisfying the position constraints.\nThe new vertex positions x' are obtained be solving the least squares problem.\nOnce again, this is a simple Poisson problem.\n\nThe resulting deformation however does not look realistic at all: the surface is badly stretched near the\nconstraints and the our deformation model is unable to create the global rotation induced by the constraints.\n\n"},{"idx":164,"label":"56","overlay":0,"note":"How to make the deformation look like the character is moving?\nHuman(-oid) motions are constrained by a skeleton making any movement a composition of rotations around joints.\nTo simulate this effect we can ask for a deformation that locally resembles to a rotation.\nThis way the deformation will seem more rigid.\n\nTo do so, we assign rotation matrices Ri at each vertex i which will affect all incident edges.\nThe least squares problem has now two sets of unknowns: the vertex positions and the rotations.\nAnd the energy tells us that for each edge ij the modified geometry e'_ij must be as close as possible to a rotation of the input edge e_ij.\nHere the cross denotes a multiplication of a 3x3 matrix R_i by a 3x1 matrix e_ij.\n\nNote that this problem is a nonlinear least squares problem but it can be solved efficiently by alternatively solving for the vertex position and solving for the rotations.\nHaving fixed rotations, solving for the vertex positions is a linear problem that can be solved by 3 separate calls to a conjugate gradients algorithm or even by using Gauß-Seidel iterations.\nFinding the rotations is a so-called orthogonal Procrustes problem which has a closed form solution:\nLet U Σ V^T  be the singular value decomposition of the 3x3 matrix built from the original geometry and current approximation of the solution, then Ri = U V^T\n\nThe resulting deformation is able to capture a global rotation of the model while the position constraints nicely spread out across the surface.\nAs always, a Python listing is available.\n\nThe takeaway message here is that many nonlinear problems can be solved as a series of linear ones.\n"},{"idx":165,"label":"56","overlay":1,"note":"How to make the deformation look like the character is moving?\nHuman(-oid) motions are constrained by a skeleton making any movement a composition of rotations around joints.\nTo simulate this effect we can ask for a deformation that locally resembles to a rotation.\nThis way the deformation will seem more rigid.\n\nTo do so, we assign rotation matrices Ri at each vertex i which will affect all incident edges.\nThe least squares problem has now two sets of unknowns: the vertex positions and the rotations.\nAnd the energy tells us that for each edge ij the modified geometry e'_ij must be as close as possible to a rotation of the input edge e_ij.\nHere the cross denotes a multiplication of a 3x3 matrix R_i by a 3x1 matrix e_ij.\n\nNote that this problem is a nonlinear least squares problem but it can be solved efficiently by alternatively solving for the vertex position and solving for the rotations.\nHaving fixed rotations, solving for the vertex positions is a linear problem that can be solved by 3 separate calls to a conjugate gradients algorithm or even by using Gauß-Seidel iterations.\nFinding the rotations is a so-called orthogonal Procrustes problem which has a closed form solution:\nLet U Σ V^T  be the singular value decomposition of the 3x3 matrix built from the original geometry and current approximation of the solution, then Ri = U V^T\n\nThe resulting deformation is able to capture a global rotation of the model while the position constraints nicely spread out across the surface.\nAs always, a Python listing is available.\n\nThe takeaway message here is that many nonlinear problems can be solved as a series of linear ones.\n"},{"idx":166,"label":"56","overlay":2,"note":"How to make the deformation look like the character is moving?\nHuman(-oid) motions are constrained by a skeleton making any movement a composition of rotations around joints.\nTo simulate this effect we can ask for a deformation that locally resembles to a rotation.\nThis way the deformation will seem more rigid.\n\nTo do so, we assign rotation matrices Ri at each vertex i which will affect all incident edges.\nThe least squares problem has now two sets of unknowns: the vertex positions and the rotations.\nAnd the energy tells us that for each edge ij the modified geometry e'_ij must be as close as possible to a rotation of the input edge e_ij.\nHere the cross denotes a multiplication of a 3x3 matrix R_i by a 3x1 matrix e_ij.\n\nNote that this problem is a nonlinear least squares problem but it can be solved efficiently by alternatively solving for the vertex position and solving for the rotations.\nHaving fixed rotations, solving for the vertex positions is a linear problem that can be solved by 3 separate calls to a conjugate gradients algorithm or even by using Gauß-Seidel iterations.\nFinding the rotations is a so-called orthogonal Procrustes problem which has a closed form solution:\nLet U Σ V^T  be the singular value decomposition of the 3x3 matrix built from the original geometry and current approximation of the solution, then Ri = U V^T\n\nThe resulting deformation is able to capture a global rotation of the model while the position constraints nicely spread out across the surface.\nAs always, a Python listing is available.\n\nThe takeaway message here is that many nonlinear problems can be solved as a series of linear ones.\n"},{"idx":167,"label":"56","overlay":3,"note":"How to make the deformation look like the character is moving?\nHuman(-oid) motions are constrained by a skeleton making any movement a composition of rotations around joints.\nTo simulate this effect we can ask for a deformation that locally resembles to a rotation.\nThis way the deformation will seem more rigid.\n\nTo do so, we assign rotation matrices Ri at each vertex i which will affect all incident edges.\nThe least squares problem has now two sets of unknowns: the vertex positions and the rotations.\nAnd the energy tells us that for each edge ij the modified geometry e'_ij must be as close as possible to a rotation of the input edge e_ij.\nHere the cross denotes a multiplication of a 3x3 matrix R_i by a 3x1 matrix e_ij.\n\nNote that this problem is a nonlinear least squares problem but it can be solved efficiently by alternatively solving for the vertex position and solving for the rotations.\nHaving fixed rotations, solving for the vertex positions is a linear problem that can be solved by 3 separate calls to a conjugate gradients algorithm or even by using Gauß-Seidel iterations.\nFinding the rotations is a so-called orthogonal Procrustes problem which has a closed form solution:\nLet U Σ V^T  be the singular value decomposition of the 3x3 matrix built from the original geometry and current approximation of the solution, then Ri = U V^T\n\nThe resulting deformation is able to capture a global rotation of the model while the position constraints nicely spread out across the surface.\nAs always, a Python listing is available.\n\nThe takeaway message here is that many nonlinear problems can be solved as a series of linear ones.\n"},{"idx":168,"label":"56","overlay":4,"note":"How to make the deformation look like the character is moving?\nHuman(-oid) motions are constrained by a skeleton making any movement a composition of rotations around joints.\nTo simulate this effect we can ask for a deformation that locally resembles to a rotation.\nThis way the deformation will seem more rigid.\n\nTo do so, we assign rotation matrices Ri at each vertex i which will affect all incident edges.\nThe least squares problem has now two sets of unknowns: the vertex positions and the rotations.\nAnd the energy tells us that for each edge ij the modified geometry e'_ij must be as close as possible to a rotation of the input edge e_ij.\nHere the cross denotes a multiplication of a 3x3 matrix R_i by a 3x1 matrix e_ij.\n\nNote that this problem is a nonlinear least squares problem but it can be solved efficiently by alternatively solving for the vertex position and solving for the rotations.\nHaving fixed rotations, solving for the vertex positions is a linear problem that can be solved by 3 separate calls to a conjugate gradients algorithm or even by using Gauß-Seidel iterations.\nFinding the rotations is a so-called orthogonal Procrustes problem which has a closed form solution:\nLet U Σ V^T  be the singular value decomposition of the 3x3 matrix built from the original geometry and current approximation of the solution, then Ri = U V^T\n\nThe resulting deformation is able to capture a global rotation of the model while the position constraints nicely spread out across the surface.\nAs always, a Python listing is available.\n\nThe takeaway message here is that many nonlinear problems can be solved as a series of linear ones.\n"},{"idx":169,"label":"56","overlay":5,"note":"How to make the deformation look like the character is moving?\nHuman(-oid) motions are constrained by a skeleton making any movement a composition of rotations around joints.\nTo simulate this effect we can ask for a deformation that locally resembles to a rotation.\nThis way the deformation will seem more rigid.\n\nTo do so, we assign rotation matrices Ri at each vertex i which will affect all incident edges.\nThe least squares problem has now two sets of unknowns: the vertex positions and the rotations.\nAnd the energy tells us that for each edge ij the modified geometry e'_ij must be as close as possible to a rotation of the input edge e_ij.\nHere the cross denotes a multiplication of a 3x3 matrix R_i by a 3x1 matrix e_ij.\n\nNote that this problem is a nonlinear least squares problem but it can be solved efficiently by alternatively solving for the vertex position and solving for the rotations.\nHaving fixed rotations, solving for the vertex positions is a linear problem that can be solved by 3 separate calls to a conjugate gradients algorithm or even by using Gauß-Seidel iterations.\nFinding the rotations is a so-called orthogonal Procrustes problem which has a closed form solution:\nLet U Σ V^T  be the singular value decomposition of the 3x3 matrix built from the original geometry and current approximation of the solution, then Ri = U V^T\n\nThe resulting deformation is able to capture a global rotation of the model while the position constraints nicely spread out across the surface.\nAs always, a Python listing is available.\n\nThe takeaway message here is that many nonlinear problems can be solved as a series of linear ones.\n"},{"idx":170,"label":"56","overlay":6,"note":"How to make the deformation look like the character is moving?\nHuman(-oid) motions are constrained by a skeleton making any movement a composition of rotations around joints.\nTo simulate this effect we can ask for a deformation that locally resembles to a rotation.\nThis way the deformation will seem more rigid.\n\nTo do so, we assign rotation matrices Ri at each vertex i which will affect all incident edges.\nThe least squares problem has now two sets of unknowns: the vertex positions and the rotations.\nAnd the energy tells us that for each edge ij the modified geometry e'_ij must be as close as possible to a rotation of the input edge e_ij.\nHere the cross denotes a multiplication of a 3x3 matrix R_i by a 3x1 matrix e_ij.\n\nNote that this problem is a nonlinear least squares problem but it can be solved efficiently by alternatively solving for the vertex position and solving for the rotations.\nHaving fixed rotations, solving for the vertex positions is a linear problem that can be solved by 3 separate calls to a conjugate gradients algorithm or even by using Gauß-Seidel iterations.\nFinding the rotations is a so-called orthogonal Procrustes problem which has a closed form solution:\nLet U Σ V^T  be the singular value decomposition of the 3x3 matrix built from the original geometry and current approximation of the solution, then Ri = U V^T\n\nThe resulting deformation is able to capture a global rotation of the model while the position constraints nicely spread out across the surface.\nAs always, a Python listing is available.\n\nThe takeaway message here is that many nonlinear problems can be solved as a series of linear ones.\n"},{"idx":171,"label":"56","overlay":7,"note":"How to make the deformation look like the character is moving?\nHuman(-oid) motions are constrained by a skeleton making any movement a composition of rotations around joints.\nTo simulate this effect we can ask for a deformation that locally resembles to a rotation.\nThis way the deformation will seem more rigid.\n\nTo do so, we assign rotation matrices Ri at each vertex i which will affect all incident edges.\nThe least squares problem has now two sets of unknowns: the vertex positions and the rotations.\nAnd the energy tells us that for each edge ij the modified geometry e'_ij must be as close as possible to a rotation of the input edge e_ij.\nHere the cross denotes a multiplication of a 3x3 matrix R_i by a 3x1 matrix e_ij.\n\nNote that this problem is a nonlinear least squares problem but it can be solved efficiently by alternatively solving for the vertex position and solving for the rotations.\nHaving fixed rotations, solving for the vertex positions is a linear problem that can be solved by 3 separate calls to a conjugate gradients algorithm or even by using Gauß-Seidel iterations.\nFinding the rotations is a so-called orthogonal Procrustes problem which has a closed form solution:\nLet U Σ V^T  be the singular value decomposition of the 3x3 matrix built from the original geometry and current approximation of the solution, then Ri = U V^T\n\nThe resulting deformation is able to capture a global rotation of the model while the position constraints nicely spread out across the surface.\nAs always, a Python listing is available.\n\nThe takeaway message here is that many nonlinear problems can be solved as a series of linear ones.\n"},{"idx":172,"label":"57","overlay":0,"note":"For our final example I have chosen least squares conformal mapping, as it is one of the simplest problems that are not separable in dimensions.\n\nA mapping of the points of the surface to the texture is defined by a mapping function from 3d space to a plane.\nBy inverting this function we can colorize the surface using a flat image drawn by an artist.\nParameterization of a surface is a problem equivalent to flattening this surface.\n\nIn our context, we are manipulating triangulated surfaces and we define a parametrization as a piecewise linear function where the pieces are the triangles.\nSuch functions are stored in texture coordinates which are the 2D coordinates of the vertices of the triangulation.\n\nIt is very difficult to define what a good parameterization is, there are many different ways to compare the quality of maps. The distortion of a mapping is defined by the Jacobian matrix. Ideally, it should be an isometric transformation, but this is an unreachable goal.\nIn continuous settings, there only exist maps that preserve angles (conformal) and maps that preserve area (authalic).\nIn this example, we manipulate discrete conformal (angle preserving) maps.\n"},{"idx":173,"label":"57","overlay":1,"note":"For our final example I have chosen least squares conformal mapping, as it is one of the simplest problems that are not separable in dimensions.\n\nA mapping of the points of the surface to the texture is defined by a mapping function from 3d space to a plane.\nBy inverting this function we can colorize the surface using a flat image drawn by an artist.\nParameterization of a surface is a problem equivalent to flattening this surface.\n\nIn our context, we are manipulating triangulated surfaces and we define a parametrization as a piecewise linear function where the pieces are the triangles.\nSuch functions are stored in texture coordinates which are the 2D coordinates of the vertices of the triangulation.\n\nIt is very difficult to define what a good parameterization is, there are many different ways to compare the quality of maps. The distortion of a mapping is defined by the Jacobian matrix. Ideally, it should be an isometric transformation, but this is an unreachable goal.\nIn continuous settings, there only exist maps that preserve angles (conformal) and maps that preserve area (authalic).\nIn this example, we manipulate discrete conformal (angle preserving) maps.\n"},{"idx":174,"label":"57","overlay":2,"note":"For our final example I have chosen least squares conformal mapping, as it is one of the simplest problems that are not separable in dimensions.\n\nA mapping of the points of the surface to the texture is defined by a mapping function from 3d space to a plane.\nBy inverting this function we can colorize the surface using a flat image drawn by an artist.\nParameterization of a surface is a problem equivalent to flattening this surface.\n\nIn our context, we are manipulating triangulated surfaces and we define a parametrization as a piecewise linear function where the pieces are the triangles.\nSuch functions are stored in texture coordinates which are the 2D coordinates of the vertices of the triangulation.\n\nIt is very difficult to define what a good parameterization is, there are many different ways to compare the quality of maps. The distortion of a mapping is defined by the Jacobian matrix. Ideally, it should be an isometric transformation, but this is an unreachable goal.\nIn continuous settings, there only exist maps that preserve angles (conformal) and maps that preserve area (authalic).\nIn this example, we manipulate discrete conformal (angle preserving) maps.\n"},{"idx":175,"label":"58","overlay":0,"note":"\nConformal maps have a very interesting feature: their distortion is locally reduced to a scaling.\nThe stretching of the map is the same in all directions (the map is called isotropic), which makes this type of parameterization relatively simple to manipulate. The conservation of angles implies that the texture (locally) is not elongated. On the other hand, the area is not conserved, implying eventual strong changes in stretching from one place to another on the surface.\n\nComputing such a mapping is a direct instantiation of the Cauchy-Riemann equations on a pair of\nreal-valued functions of two real variables u(x, y) and v(x, y) representing the texture coordinates.\n\nIn this form, the equations correspond structurally to the condition that the Jacobian matrix is antisymmetric. Geometrically, such a matrix is always the composition of a rotation with a scaling, and in particular preserves angles. The Jacobian of a vector function (u, v) takes infinitesimal line segments at the intersection of two curves in the parameter plane (x, y) and rotates them to the corresponding segments in u, v.\nConsequently, a function satisfying the Cauchy–Riemann equations, with a nonzero derivative,\npreserves the angle between curves in the plane.\nThat is, the Cauchy–Riemann equations are the conditions for a function to be conformal.\n\n\nOf course, there will be no exact solution for a triangle mesh, therefore, as usual, we can sum failure of this relationship to hold over all triangles.\n\nWe sample tex coord at vertices, and interpolate linearly inside triangles. It also means that the Jacobian matrix is constant per triangle.\n\nNote that there is a very handy formula to compute a gradient of a linear scalar function u sampled at three vertices of a triangle.\n\nWith the help of this formula, we can write our objective function as follows:\nwe want to compute a scalar function u and a scalar function v such that the gradient of u is equal to the gradient of v rotated by 90 degrees.\n\nOf course, we can not do better than u(x, y) = v(x, y) = 0, and such a map is unsatisfactory.\n"},{"idx":176,"label":"58","overlay":1,"note":"\nConformal maps have a very interesting feature: their distortion is locally reduced to a scaling.\nThe stretching of the map is the same in all directions (the map is called isotropic), which makes this type of parameterization relatively simple to manipulate. The conservation of angles implies that the texture (locally) is not elongated. On the other hand, the area is not conserved, implying eventual strong changes in stretching from one place to another on the surface.\n\nComputing such a mapping is a direct instantiation of the Cauchy-Riemann equations on a pair of\nreal-valued functions of two real variables u(x, y) and v(x, y) representing the texture coordinates.\n\nIn this form, the equations correspond structurally to the condition that the Jacobian matrix is antisymmetric. Geometrically, such a matrix is always the composition of a rotation with a scaling, and in particular preserves angles. The Jacobian of a vector function (u, v) takes infinitesimal line segments at the intersection of two curves in the parameter plane (x, y) and rotates them to the corresponding segments in u, v.\nConsequently, a function satisfying the Cauchy–Riemann equations, with a nonzero derivative,\npreserves the angle between curves in the plane.\nThat is, the Cauchy–Riemann equations are the conditions for a function to be conformal.\n\n\nOf course, there will be no exact solution for a triangle mesh, therefore, as usual, we can sum failure of this relationship to hold over all triangles.\n\nWe sample tex coord at vertices, and interpolate linearly inside triangles. It also means that the Jacobian matrix is constant per triangle.\n\nNote that there is a very handy formula to compute a gradient of a linear scalar function u sampled at three vertices of a triangle.\n\nWith the help of this formula, we can write our objective function as follows:\nwe want to compute a scalar function u and a scalar function v such that the gradient of u is equal to the gradient of v rotated by 90 degrees.\n\nOf course, we can not do better than u(x, y) = v(x, y) = 0, and such a map is unsatisfactory.\n"},{"idx":177,"label":"58","overlay":2,"note":"\nConformal maps have a very interesting feature: their distortion is locally reduced to a scaling.\nThe stretching of the map is the same in all directions (the map is called isotropic), which makes this type of parameterization relatively simple to manipulate. The conservation of angles implies that the texture (locally) is not elongated. On the other hand, the area is not conserved, implying eventual strong changes in stretching from one place to another on the surface.\n\nComputing such a mapping is a direct instantiation of the Cauchy-Riemann equations on a pair of\nreal-valued functions of two real variables u(x, y) and v(x, y) representing the texture coordinates.\n\nIn this form, the equations correspond structurally to the condition that the Jacobian matrix is antisymmetric. Geometrically, such a matrix is always the composition of a rotation with a scaling, and in particular preserves angles. The Jacobian of a vector function (u, v) takes infinitesimal line segments at the intersection of two curves in the parameter plane (x, y) and rotates them to the corresponding segments in u, v.\nConsequently, a function satisfying the Cauchy–Riemann equations, with a nonzero derivative,\npreserves the angle between curves in the plane.\nThat is, the Cauchy–Riemann equations are the conditions for a function to be conformal.\n\n\nOf course, there will be no exact solution for a triangle mesh, therefore, as usual, we can sum failure of this relationship to hold over all triangles.\n\nWe sample tex coord at vertices, and interpolate linearly inside triangles. It also means that the Jacobian matrix is constant per triangle.\n\nNote that there is a very handy formula to compute a gradient of a linear scalar function u sampled at three vertices of a triangle.\n\nWith the help of this formula, we can write our objective function as follows:\nwe want to compute a scalar function u and a scalar function v such that the gradient of u is equal to the gradient of v rotated by 90 degrees.\n\nOf course, we can not do better than u(x, y) = v(x, y) = 0, and such a map is unsatisfactory.\n"},{"idx":178,"label":"58","overlay":3,"note":"\nConformal maps have a very interesting feature: their distortion is locally reduced to a scaling.\nThe stretching of the map is the same in all directions (the map is called isotropic), which makes this type of parameterization relatively simple to manipulate. The conservation of angles implies that the texture (locally) is not elongated. On the other hand, the area is not conserved, implying eventual strong changes in stretching from one place to another on the surface.\n\nComputing such a mapping is a direct instantiation of the Cauchy-Riemann equations on a pair of\nreal-valued functions of two real variables u(x, y) and v(x, y) representing the texture coordinates.\n\nIn this form, the equations correspond structurally to the condition that the Jacobian matrix is antisymmetric. Geometrically, such a matrix is always the composition of a rotation with a scaling, and in particular preserves angles. The Jacobian of a vector function (u, v) takes infinitesimal line segments at the intersection of two curves in the parameter plane (x, y) and rotates them to the corresponding segments in u, v.\nConsequently, a function satisfying the Cauchy–Riemann equations, with a nonzero derivative,\npreserves the angle between curves in the plane.\nThat is, the Cauchy–Riemann equations are the conditions for a function to be conformal.\n\n\nOf course, there will be no exact solution for a triangle mesh, therefore, as usual, we can sum failure of this relationship to hold over all triangles.\n\nWe sample tex coord at vertices, and interpolate linearly inside triangles. It also means that the Jacobian matrix is constant per triangle.\n\nNote that there is a very handy formula to compute a gradient of a linear scalar function u sampled at three vertices of a triangle.\n\nWith the help of this formula, we can write our objective function as follows:\nwe want to compute a scalar function u and a scalar function v such that the gradient of u is equal to the gradient of v rotated by 90 degrees.\n\nOf course, we can not do better than u(x, y) = v(x, y) = 0, and such a map is unsatisfactory.\n"},{"idx":179,"label":"58","overlay":4,"note":"\nConformal maps have a very interesting feature: their distortion is locally reduced to a scaling.\nThe stretching of the map is the same in all directions (the map is called isotropic), which makes this type of parameterization relatively simple to manipulate. The conservation of angles implies that the texture (locally) is not elongated. On the other hand, the area is not conserved, implying eventual strong changes in stretching from one place to another on the surface.\n\nComputing such a mapping is a direct instantiation of the Cauchy-Riemann equations on a pair of\nreal-valued functions of two real variables u(x, y) and v(x, y) representing the texture coordinates.\n\nIn this form, the equations correspond structurally to the condition that the Jacobian matrix is antisymmetric. Geometrically, such a matrix is always the composition of a rotation with a scaling, and in particular preserves angles. The Jacobian of a vector function (u, v) takes infinitesimal line segments at the intersection of two curves in the parameter plane (x, y) and rotates them to the corresponding segments in u, v.\nConsequently, a function satisfying the Cauchy–Riemann equations, with a nonzero derivative,\npreserves the angle between curves in the plane.\nThat is, the Cauchy–Riemann equations are the conditions for a function to be conformal.\n\n\nOf course, there will be no exact solution for a triangle mesh, therefore, as usual, we can sum failure of this relationship to hold over all triangles.\n\nWe sample tex coord at vertices, and interpolate linearly inside triangles. It also means that the Jacobian matrix is constant per triangle.\n\nNote that there is a very handy formula to compute a gradient of a linear scalar function u sampled at three vertices of a triangle.\n\nWith the help of this formula, we can write our objective function as follows:\nwe want to compute a scalar function u and a scalar function v such that the gradient of u is equal to the gradient of v rotated by 90 degrees.\n\nOf course, we can not do better than u(x, y) = v(x, y) = 0, and such a map is unsatisfactory.\n"},{"idx":180,"label":"59","overlay":0,"note":"As a quick hack, we can \"pin\" two arbitrary vertices to some arbitrary points in the u, v plane. Pinning one vertex determines\ntranslation in the plane of the texture, whereas the other determines rotation and scale.\nThis energy is very easy to minimize, just as before we need to solve a linear system.\n\n"},{"idx":181,"label":"59","overlay":1,"note":"As a quick hack, we can \"pin\" two arbitrary vertices to some arbitrary points in the u, v plane. Pinning one vertex determines\ntranslation in the plane of the texture, whereas the other determines rotation and scale.\nThis energy is very easy to minimize, just as before we need to solve a linear system.\n\n"},{"idx":182,"label":"60","overlay":0,"note":"This concludes our least squares through examples section.\nThe main thing to recall here is that stating a problem as an optimization problem is a very powerful tool.\n\nBasically, we do not seek for an algorithm to compute a solution.\nWe describe what a solution should look like, and then let the solver do all the job.\nDifferent variations of Laplace's and Poisson's problem are omnipresent, and you should learn to recognize them.\nSome problems are separable in dimensions, some are not. Some problems are linear, some are not, but a fair portion of non-linear problems can be linearized, as we will see very shortly.\n\n\nHere goes our last section entitled \"From least squares to neural networks\"\n\nNowadays machine learning is a very trendy topic, almost everyone wants to use it somehow, whether it is\nreasonable or not. Machine learning seems to be the answer to all the business prayers. It is amazing how\npeople are now diving into the abyss of neural networks without ever looking back. However, it is much\nmore surprising to witness the existence of two irreconcilable camps: those for whom neural networks are\nthe answer to the meaning of life, the universe, and everything, and those who despise neural networks and\ndeny the right to use the tool. We do not advocate for either party; two main points of this chapters are:\n• neural networks are not the only machine learning tool;\n• there is no clear boundary between least squares methods and neural networks.\n"},{"idx":183,"label":"61","overlay":0,"note":"The most simple, standard and yet quite common machine learning problem is binary classification. Many\nvery interesting and important problems can be reduced to it. For example, we are given a set of data where\nn vectors are each marked with a “red” or “green” label. This is the simplest example, but in practice the\nred/green dataset can be really useful: for example, “spam”/“not spam” email classification, where the input\nvectors encode various characteristics of the content (e.g. the number of mentions of a certain magic carpet\ncleaning solution).\n\nOur goal in binary classification is to build a function that takes a vector as an input and predicts its\nlabel. First we need to learn from the database: we need to build such a function whose predictions match\nthe database labels. In the end, once the function is constructed, we can discard the database and use the\nfunction we have built as an oracle to predict labels for previously unseen vectors.\nLong story short, let us consider the simplest example: we have n real numbers and the corresponding\ncolors that we encode as 0 (“red”) and 1 (“green”). In other words, we have a sequence {(xi, yi )}ni=1 as the\ninput, where xi ∈ R and yi ∈ {0, 1}. How do we build the classifying function? Let us start with the basics:\nwe can fit a straight line to the set of input points {(xi , yi )}ni=1 , thus performing an ordinary\nlinear regression:\n\nNext we endow the straight line with the classification rule: if y(x) > 1/2 then x is green, otherwise it is red. The bottom image provides an example: the colored dots show the database; the straight line is the linear regression result, and the decision boundary is shown by the dashed line. All points on the right of the line are classified as green, and on the left as red. We can see that the database is perfectly learned, and there is no misclassification in the database (for the sake of simplicity, we do not make the distinction between the database we learn on and the database we use to assess the quality of the classifying function).\n\n[show code]\n\nIt may sound stupid, but ordinary linear regression is not always a bad choice for a binary classification. Of course, it only works well if certain assumptions about the input data are satisfied (e.g. independent and normally distributed class samples). If, however, these assumptions are not met, we may face problems. In this example, we have added to the previous database few more “green” samples. This affects the linear regression, and we encounter misclassified database entries even if the database is perfectly separable. We can fix the situation by fitting a nonlinear model; to do so, first let us meet the logistic growth model before we return to the classification.\n"},{"idx":184,"label":"61","overlay":1,"note":"The most simple, standard and yet quite common machine learning problem is binary classification. Many\nvery interesting and important problems can be reduced to it. For example, we are given a set of data where\nn vectors are each marked with a “red” or “green” label. This is the simplest example, but in practice the\nred/green dataset can be really useful: for example, “spam”/“not spam” email classification, where the input\nvectors encode various characteristics of the content (e.g. the number of mentions of a certain magic carpet\ncleaning solution).\n\nOur goal in binary classification is to build a function that takes a vector as an input and predicts its\nlabel. First we need to learn from the database: we need to build such a function whose predictions match\nthe database labels. In the end, once the function is constructed, we can discard the database and use the\nfunction we have built as an oracle to predict labels for previously unseen vectors.\nLong story short, let us consider the simplest example: we have n real numbers and the corresponding\ncolors that we encode as 0 (“red”) and 1 (“green”). In other words, we have a sequence {(xi, yi )}ni=1 as the\ninput, where xi ∈ R and yi ∈ {0, 1}. How do we build the classifying function? Let us start with the basics:\nwe can fit a straight line to the set of input points {(xi , yi )}ni=1 , thus performing an ordinary\nlinear regression:\n\nNext we endow the straight line with the classification rule: if y(x) > 1/2 then x is green, otherwise it is red. The bottom image provides an example: the colored dots show the database; the straight line is the linear regression result, and the decision boundary is shown by the dashed line. All points on the right of the line are classified as green, and on the left as red. We can see that the database is perfectly learned, and there is no misclassification in the database (for the sake of simplicity, we do not make the distinction between the database we learn on and the database we use to assess the quality of the classifying function).\n\n[show code]\n\nIt may sound stupid, but ordinary linear regression is not always a bad choice for a binary classification. Of course, it only works well if certain assumptions about the input data are satisfied (e.g. independent and normally distributed class samples). If, however, these assumptions are not met, we may face problems. In this example, we have added to the previous database few more “green” samples. This affects the linear regression, and we encounter misclassified database entries even if the database is perfectly separable. We can fix the situation by fitting a nonlinear model; to do so, first let us meet the logistic growth model before we return to the classification.\n"},{"idx":185,"label":"61","overlay":2,"note":"The most simple, standard and yet quite common machine learning problem is binary classification. Many\nvery interesting and important problems can be reduced to it. For example, we are given a set of data where\nn vectors are each marked with a “red” or “green” label. This is the simplest example, but in practice the\nred/green dataset can be really useful: for example, “spam”/“not spam” email classification, where the input\nvectors encode various characteristics of the content (e.g. the number of mentions of a certain magic carpet\ncleaning solution).\n\nOur goal in binary classification is to build a function that takes a vector as an input and predicts its\nlabel. First we need to learn from the database: we need to build such a function whose predictions match\nthe database labels. In the end, once the function is constructed, we can discard the database and use the\nfunction we have built as an oracle to predict labels for previously unseen vectors.\nLong story short, let us consider the simplest example: we have n real numbers and the corresponding\ncolors that we encode as 0 (“red”) and 1 (“green”). In other words, we have a sequence {(xi, yi )}ni=1 as the\ninput, where xi ∈ R and yi ∈ {0, 1}. How do we build the classifying function? Let us start with the basics:\nwe can fit a straight line to the set of input points {(xi , yi )}ni=1 , thus performing an ordinary\nlinear regression:\n\nNext we endow the straight line with the classification rule: if y(x) > 1/2 then x is green, otherwise it is red. The bottom image provides an example: the colored dots show the database; the straight line is the linear regression result, and the decision boundary is shown by the dashed line. All points on the right of the line are classified as green, and on the left as red. We can see that the database is perfectly learned, and there is no misclassification in the database (for the sake of simplicity, we do not make the distinction between the database we learn on and the database we use to assess the quality of the classifying function).\n\n[show code]\n\nIt may sound stupid, but ordinary linear regression is not always a bad choice for a binary classification. Of course, it only works well if certain assumptions about the input data are satisfied (e.g. independent and normally distributed class samples). If, however, these assumptions are not met, we may face problems. In this example, we have added to the previous database few more “green” samples. This affects the linear regression, and we encounter misclassified database entries even if the database is perfectly separable. We can fix the situation by fitting a nonlinear model; to do so, first let us meet the logistic growth model before we return to the classification.\n"},{"idx":186,"label":"61","overlay":3,"note":"The most simple, standard and yet quite common machine learning problem is binary classification. Many\nvery interesting and important problems can be reduced to it. For example, we are given a set of data where\nn vectors are each marked with a “red” or “green” label. This is the simplest example, but in practice the\nred/green dataset can be really useful: for example, “spam”/“not spam” email classification, where the input\nvectors encode various characteristics of the content (e.g. the number of mentions of a certain magic carpet\ncleaning solution).\n\nOur goal in binary classification is to build a function that takes a vector as an input and predicts its\nlabel. First we need to learn from the database: we need to build such a function whose predictions match\nthe database labels. In the end, once the function is constructed, we can discard the database and use the\nfunction we have built as an oracle to predict labels for previously unseen vectors.\nLong story short, let us consider the simplest example: we have n real numbers and the corresponding\ncolors that we encode as 0 (“red”) and 1 (“green”). In other words, we have a sequence {(xi, yi )}ni=1 as the\ninput, where xi ∈ R and yi ∈ {0, 1}. How do we build the classifying function? Let us start with the basics:\nwe can fit a straight line to the set of input points {(xi , yi )}ni=1 , thus performing an ordinary\nlinear regression:\n\nNext we endow the straight line with the classification rule: if y(x) > 1/2 then x is green, otherwise it is red. The bottom image provides an example: the colored dots show the database; the straight line is the linear regression result, and the decision boundary is shown by the dashed line. All points on the right of the line are classified as green, and on the left as red. We can see that the database is perfectly learned, and there is no misclassification in the database (for the sake of simplicity, we do not make the distinction between the database we learn on and the database we use to assess the quality of the classifying function).\n\n[show code]\n\nIt may sound stupid, but ordinary linear regression is not always a bad choice for a binary classification. Of course, it only works well if certain assumptions about the input data are satisfied (e.g. independent and normally distributed class samples). If, however, these assumptions are not met, we may face problems. In this example, we have added to the previous database few more “green” samples. This affects the linear regression, and we encounter misclassified database entries even if the database is perfectly separable. We can fix the situation by fitting a nonlinear model; to do so, first let us meet the logistic growth model before we return to the classification.\n"},{"idx":187,"label":"61","overlay":4,"note":"The most simple, standard and yet quite common machine learning problem is binary classification. Many\nvery interesting and important problems can be reduced to it. For example, we are given a set of data where\nn vectors are each marked with a “red” or “green” label. This is the simplest example, but in practice the\nred/green dataset can be really useful: for example, “spam”/“not spam” email classification, where the input\nvectors encode various characteristics of the content (e.g. the number of mentions of a certain magic carpet\ncleaning solution).\n\nOur goal in binary classification is to build a function that takes a vector as an input and predicts its\nlabel. First we need to learn from the database: we need to build such a function whose predictions match\nthe database labels. In the end, once the function is constructed, we can discard the database and use the\nfunction we have built as an oracle to predict labels for previously unseen vectors.\nLong story short, let us consider the simplest example: we have n real numbers and the corresponding\ncolors that we encode as 0 (“red”) and 1 (“green”). In other words, we have a sequence {(xi, yi )}ni=1 as the\ninput, where xi ∈ R and yi ∈ {0, 1}. How do we build the classifying function? Let us start with the basics:\nwe can fit a straight line to the set of input points {(xi , yi )}ni=1 , thus performing an ordinary\nlinear regression:\n\nNext we endow the straight line with the classification rule: if y(x) > 1/2 then x is green, otherwise it is red. The bottom image provides an example: the colored dots show the database; the straight line is the linear regression result, and the decision boundary is shown by the dashed line. All points on the right of the line are classified as green, and on the left as red. We can see that the database is perfectly learned, and there is no misclassification in the database (for the sake of simplicity, we do not make the distinction between the database we learn on and the database we use to assess the quality of the classifying function).\n\n[show code]\n\nIt may sound stupid, but ordinary linear regression is not always a bad choice for a binary classification. Of course, it only works well if certain assumptions about the input data are satisfied (e.g. independent and normally distributed class samples). If, however, these assumptions are not met, we may face problems. In this example, we have added to the previous database few more “green” samples. This affects the linear regression, and we encounter misclassified database entries even if the database is perfectly separable. We can fix the situation by fitting a nonlinear model; to do so, first let us meet the logistic growth model before we return to the classification.\n"},{"idx":188,"label":"62","overlay":0,"note":"Logistic growth functions are useful as models accounting for constraints placed on the growth. An example\nis a bacteria culture allowed to grow under initially ideal conditions, followed by less favorable conditions\nthat inhibit growth. Imagine a colony of the bacteria B. dendroides is growing in a Petri dish. The colony’s\narea a (in square centimeters) can be modeled as a function of t, the elapsed time in hours.\n\nHere c is the carrying capacity, w0 is the initial population size and w is the growth rate.\n\nLet us say that we want to recover the parameters of the model from an experiment: we have a series of\nn measurements (ai, ti ), as shown in the scatter plot.\n\nUnder the assumption of independent and normally distributed errors, with 0 expectations and common\nvariance, maximizing the likelyhood for the general nonlinear modelis equivalent to the minimization\nof the sum of squared errors:\n\n"},{"idx":189,"label":"62","overlay":1,"note":"Logistic growth functions are useful as models accounting for constraints placed on the growth. An example\nis a bacteria culture allowed to grow under initially ideal conditions, followed by less favorable conditions\nthat inhibit growth. Imagine a colony of the bacteria B. dendroides is growing in a Petri dish. The colony’s\narea a (in square centimeters) can be modeled as a function of t, the elapsed time in hours.\n\nHere c is the carrying capacity, w0 is the initial population size and w is the growth rate.\n\nLet us say that we want to recover the parameters of the model from an experiment: we have a series of\nn measurements (ai, ti ), as shown in the scatter plot.\n\nUnder the assumption of independent and normally distributed errors, with 0 expectations and common\nvariance, maximizing the likelyhood for the general nonlinear modelis equivalent to the minimization\nof the sum of squared errors:\n\n"},{"idx":190,"label":"62","overlay":2,"note":"Logistic growth functions are useful as models accounting for constraints placed on the growth. An example\nis a bacteria culture allowed to grow under initially ideal conditions, followed by less favorable conditions\nthat inhibit growth. Imagine a colony of the bacteria B. dendroides is growing in a Petri dish. The colony’s\narea a (in square centimeters) can be modeled as a function of t, the elapsed time in hours.\n\nHere c is the carrying capacity, w0 is the initial population size and w is the growth rate.\n\nLet us say that we want to recover the parameters of the model from an experiment: we have a series of\nn measurements (ai, ti ), as shown in the scatter plot.\n\nUnder the assumption of independent and normally distributed errors, with 0 expectations and common\nvariance, maximizing the likelyhood for the general nonlinear modelis equivalent to the minimization\nof the sum of squared errors:\n\n"},{"idx":191,"label":"63","overlay":0,"note":"There are multiple ways to deal with nonlinearities of the model, for example, we can try to apply some\ntransformation to the model prior the fitting. Let us try it\n\nIf we have an estimation for the parameter c, this model is well suited for an ordinary linear regression.\nWe can find an estimation for the parameters w0 and w by solving the following system in the least squares sense:\n\nHow can we estimate c(0)? Knowing that it corresponds to the carrying capacity, we can do a quick and\ndirty estimation c(0) := max ai + ε, where a small constant ε is added in order to avoid division by zero\n\n[show code]\n\nAnd here is the logistic curve fitted to our data. Of course, the fitting is far from being ideal: we have estimated the distance from the points ai to the curve a(ti ) in a very indirect and distoring way. Nevertheless, this fitting can be of use as a first guess for a further optimization. \n"},{"idx":192,"label":"63","overlay":1,"note":"There are multiple ways to deal with nonlinearities of the model, for example, we can try to apply some\ntransformation to the model prior the fitting. Let us try it\n\nIf we have an estimation for the parameter c, this model is well suited for an ordinary linear regression.\nWe can find an estimation for the parameters w0 and w by solving the following system in the least squares sense:\n\nHow can we estimate c(0)? Knowing that it corresponds to the carrying capacity, we can do a quick and\ndirty estimation c(0) := max ai + ε, where a small constant ε is added in order to avoid division by zero\n\n[show code]\n\nAnd here is the logistic curve fitted to our data. Of course, the fitting is far from being ideal: we have estimated the distance from the points ai to the curve a(ti ) in a very indirect and distoring way. Nevertheless, this fitting can be of use as a first guess for a further optimization. \n"},{"idx":193,"label":"63","overlay":2,"note":"There are multiple ways to deal with nonlinearities of the model, for example, we can try to apply some\ntransformation to the model prior the fitting. Let us try it\n\nIf we have an estimation for the parameter c, this model is well suited for an ordinary linear regression.\nWe can find an estimation for the parameters w0 and w by solving the following system in the least squares sense:\n\nHow can we estimate c(0)? Knowing that it corresponds to the carrying capacity, we can do a quick and\ndirty estimation c(0) := max ai + ε, where a small constant ε is added in order to avoid division by zero\n\n[show code]\n\nAnd here is the logistic curve fitted to our data. Of course, the fitting is far from being ideal: we have estimated the distance from the points ai to the curve a(ti ) in a very indirect and distoring way. Nevertheless, this fitting can be of use as a first guess for a further optimization. \n"},{"idx":194,"label":"63","overlay":3,"note":"There are multiple ways to deal with nonlinearities of the model, for example, we can try to apply some\ntransformation to the model prior the fitting. Let us try it\n\nIf we have an estimation for the parameter c, this model is well suited for an ordinary linear regression.\nWe can find an estimation for the parameters w0 and w by solving the following system in the least squares sense:\n\nHow can we estimate c(0)? Knowing that it corresponds to the carrying capacity, we can do a quick and\ndirty estimation c(0) := max ai + ε, where a small constant ε is added in order to avoid division by zero\n\n[show code]\n\nAnd here is the logistic curve fitted to our data. Of course, the fitting is far from being ideal: we have estimated the distance from the points ai to the curve a(ti ) in a very indirect and distoring way. Nevertheless, this fitting can be of use as a first guess for a further optimization. \n"},{"idx":195,"label":"63","overlay":4,"note":"There are multiple ways to deal with nonlinearities of the model, for example, we can try to apply some\ntransformation to the model prior the fitting. Let us try it\n\nIf we have an estimation for the parameter c, this model is well suited for an ordinary linear regression.\nWe can find an estimation for the parameters w0 and w by solving the following system in the least squares sense:\n\nHow can we estimate c(0)? Knowing that it corresponds to the carrying capacity, we can do a quick and\ndirty estimation c(0) := max ai + ε, where a small constant ε is added in order to avoid division by zero\n\n[show code]\n\nAnd here is the logistic curve fitted to our data. Of course, the fitting is far from being ideal: we have estimated the distance from the points ai to the curve a(ti ) in a very indirect and distoring way. Nevertheless, this fitting can be of use as a first guess for a further optimization. \n"},{"idx":196,"label":"63","overlay":5,"note":"There are multiple ways to deal with nonlinearities of the model, for example, we can try to apply some\ntransformation to the model prior the fitting. Let us try it\n\nIf we have an estimation for the parameter c, this model is well suited for an ordinary linear regression.\nWe can find an estimation for the parameters w0 and w by solving the following system in the least squares sense:\n\nHow can we estimate c(0)? Knowing that it corresponds to the carrying capacity, we can do a quick and\ndirty estimation c(0) := max ai + ε, where a small constant ε is added in order to avoid division by zero\n\n[show code]\n\nAnd here is the logistic curve fitted to our data. Of course, the fitting is far from being ideal: we have estimated the distance from the points ai to the curve a(ti ) in a very indirect and distoring way. Nevertheless, this fitting can be of use as a first guess for a further optimization. \n"},{"idx":197,"label":"63","overlay":6,"note":"There are multiple ways to deal with nonlinearities of the model, for example, we can try to apply some\ntransformation to the model prior the fitting. Let us try it\n\nIf we have an estimation for the parameter c, this model is well suited for an ordinary linear regression.\nWe can find an estimation for the parameters w0 and w by solving the following system in the least squares sense:\n\nHow can we estimate c(0)? Knowing that it corresponds to the carrying capacity, we can do a quick and\ndirty estimation c(0) := max ai + ε, where a small constant ε is added in order to avoid division by zero\n\n[show code]\n\nAnd here is the logistic curve fitted to our data. Of course, the fitting is far from being ideal: we have estimated the distance from the points ai to the curve a(ti ) in a very indirect and distoring way. Nevertheless, this fitting can be of use as a first guess for a further optimization. \n"},{"idx":198,"label":"64","overlay":0,"note":"Let us denote by r the residual between the input label and the prediction. Then our problem can be rewritten as a minimization of the squared norm of the residual vector.\n\nWe can solv it  by the Gauß–Newton algorithm. The idea is extremely simple: starting from the\ninitial guess b, for example, \nthe one we have built by the ordinary least squares on the transformed model (or even just three random values), we build a sequence of approximations \nTo find the increment, we can linearize the function r at the point b^k:\n\nHere Jr is the n x 3 Jacobian matrix evaluated at point b^k.\nThen we are looking for such an increment vector ∆b(k) that the squared norm of the residual is minimized:\n\nThis again is an ordinary least squares problem equivalent to solving a 3 × 3 system of linear equations.\n\nHere is the logistic curve fitted to our data by solving a series of least squares problems.\n[show the code]\n"},{"idx":199,"label":"64","overlay":1,"note":"Let us denote by r the residual between the input label and the prediction. Then our problem can be rewritten as a minimization of the squared norm of the residual vector.\n\nWe can solv it  by the Gauß–Newton algorithm. The idea is extremely simple: starting from the\ninitial guess b, for example, \nthe one we have built by the ordinary least squares on the transformed model (or even just three random values), we build a sequence of approximations \nTo find the increment, we can linearize the function r at the point b^k:\n\nHere Jr is the n x 3 Jacobian matrix evaluated at point b^k.\nThen we are looking for such an increment vector ∆b(k) that the squared norm of the residual is minimized:\n\nThis again is an ordinary least squares problem equivalent to solving a 3 × 3 system of linear equations.\n\nHere is the logistic curve fitted to our data by solving a series of least squares problems.\n[show the code]\n"},{"idx":200,"label":"64","overlay":2,"note":"Let us denote by r the residual between the input label and the prediction. Then our problem can be rewritten as a minimization of the squared norm of the residual vector.\n\nWe can solv it  by the Gauß–Newton algorithm. The idea is extremely simple: starting from the\ninitial guess b, for example, \nthe one we have built by the ordinary least squares on the transformed model (or even just three random values), we build a sequence of approximations \nTo find the increment, we can linearize the function r at the point b^k:\n\nHere Jr is the n x 3 Jacobian matrix evaluated at point b^k.\nThen we are looking for such an increment vector ∆b(k) that the squared norm of the residual is minimized:\n\nThis again is an ordinary least squares problem equivalent to solving a 3 × 3 system of linear equations.\n\nHere is the logistic curve fitted to our data by solving a series of least squares problems.\n[show the code]\n"},{"idx":201,"label":"64","overlay":3,"note":"Let us denote by r the residual between the input label and the prediction. Then our problem can be rewritten as a minimization of the squared norm of the residual vector.\n\nWe can solv it  by the Gauß–Newton algorithm. The idea is extremely simple: starting from the\ninitial guess b, for example, \nthe one we have built by the ordinary least squares on the transformed model (or even just three random values), we build a sequence of approximations \nTo find the increment, we can linearize the function r at the point b^k:\n\nHere Jr is the n x 3 Jacobian matrix evaluated at point b^k.\nThen we are looking for such an increment vector ∆b(k) that the squared norm of the residual is minimized:\n\nThis again is an ordinary least squares problem equivalent to solving a 3 × 3 system of linear equations.\n\nHere is the logistic curve fitted to our data by solving a series of least squares problems.\n[show the code]\n"},{"idx":202,"label":"64","overlay":4,"note":"Let us denote by r the residual between the input label and the prediction. Then our problem can be rewritten as a minimization of the squared norm of the residual vector.\n\nWe can solv it  by the Gauß–Newton algorithm. The idea is extremely simple: starting from the\ninitial guess b, for example, \nthe one we have built by the ordinary least squares on the transformed model (or even just three random values), we build a sequence of approximations \nTo find the increment, we can linearize the function r at the point b^k:\n\nHere Jr is the n x 3 Jacobian matrix evaluated at point b^k.\nThen we are looking for such an increment vector ∆b(k) that the squared norm of the residual is minimized:\n\nThis again is an ordinary least squares problem equivalent to solving a 3 × 3 system of linear equations.\n\nHere is the logistic curve fitted to our data by solving a series of least squares problems.\n[show the code]\n"},{"idx":203,"label":"64","overlay":5,"note":"Let us denote by r the residual between the input label and the prediction. Then our problem can be rewritten as a minimization of the squared norm of the residual vector.\n\nWe can solv it  by the Gauß–Newton algorithm. The idea is extremely simple: starting from the\ninitial guess b, for example, \nthe one we have built by the ordinary least squares on the transformed model (or even just three random values), we build a sequence of approximations \nTo find the increment, we can linearize the function r at the point b^k:\n\nHere Jr is the n x 3 Jacobian matrix evaluated at point b^k.\nThen we are looking for such an increment vector ∆b(k) that the squared norm of the residual is minimized:\n\nThis again is an ordinary least squares problem equivalent to solving a 3 × 3 system of linear equations.\n\nHere is the logistic curve fitted to our data by solving a series of least squares problems.\n[show the code]\n"},{"idx":204,"label":"64","overlay":6,"note":"Let us denote by r the residual between the input label and the prediction. Then our problem can be rewritten as a minimization of the squared norm of the residual vector.\n\nWe can solv it  by the Gauß–Newton algorithm. The idea is extremely simple: starting from the\ninitial guess b, for example, \nthe one we have built by the ordinary least squares on the transformed model (or even just three random values), we build a sequence of approximations \nTo find the increment, we can linearize the function r at the point b^k:\n\nHere Jr is the n x 3 Jacobian matrix evaluated at point b^k.\nThen we are looking for such an increment vector ∆b(k) that the squared norm of the residual is minimized:\n\nThis again is an ordinary least squares problem equivalent to solving a 3 × 3 system of linear equations.\n\nHere is the logistic curve fitted to our data by solving a series of least squares problems.\n[show the code]\n"},{"idx":205,"label":"65","overlay":0,"note":"Back to our classification example, fitting a sigmoid shows a clear advantage over ordinary linear regression classifier.\n\n\nIn our example the training sets are linearly separable, and thus we did not have any misclassification\nin the training set. There is a caveat though. It might seem that linear separability is good news for binary\nclassification: linear separability means that the problem is easy in some sense and that learning algorithms\nhave a clear and achievable goal. Consider the fact that the decision boundary in a linear classifier is\nindependent of the scale of the parameters. \n\nFor instance, in the above example, the decision boundary is given by t such that 1/2 = 1/(1+exp(-wt - w0)).\nSolving this simple equation for t we get t = w0/w . The decision boundary would not move a tiny bit if we multiply both w0 and w by a constant superior to 1. The boundary does not move, however, the scale does impact the likelihood in logistic regression by causing the logistic function to become more steep. If we have found such a decision boundary that all the samples from the learning database are correctly classified, we can infinitely scale the weights w and w0 , pushing the predictions closer and closer to their correct labels. The logistic function thus converges to the Heaviside step function. It is one of numerous possible instances of what is called overfitting: the model is becoming overconfident about the data and uses very large weights to describe it. There is a very simple solution to this problem: regularize the weights. The most basic regularization is to add a simple term that penalizes large weights.\n\n"},{"idx":206,"label":"65","overlay":1,"note":"Back to our classification example, fitting a sigmoid shows a clear advantage over ordinary linear regression classifier.\n\n\nIn our example the training sets are linearly separable, and thus we did not have any misclassification\nin the training set. There is a caveat though. It might seem that linear separability is good news for binary\nclassification: linear separability means that the problem is easy in some sense and that learning algorithms\nhave a clear and achievable goal. Consider the fact that the decision boundary in a linear classifier is\nindependent of the scale of the parameters. \n\nFor instance, in the above example, the decision boundary is given by t such that 1/2 = 1/(1+exp(-wt - w0)).\nSolving this simple equation for t we get t = w0/w . The decision boundary would not move a tiny bit if we multiply both w0 and w by a constant superior to 1. The boundary does not move, however, the scale does impact the likelihood in logistic regression by causing the logistic function to become more steep. If we have found such a decision boundary that all the samples from the learning database are correctly classified, we can infinitely scale the weights w and w0 , pushing the predictions closer and closer to their correct labels. The logistic function thus converges to the Heaviside step function. It is one of numerous possible instances of what is called overfitting: the model is becoming overconfident about the data and uses very large weights to describe it. There is a very simple solution to this problem: regularize the weights. The most basic regularization is to add a simple term that penalizes large weights.\n\n"},{"idx":207,"label":"65","overlay":2,"note":"Back to our classification example, fitting a sigmoid shows a clear advantage over ordinary linear regression classifier.\n\n\nIn our example the training sets are linearly separable, and thus we did not have any misclassification\nin the training set. There is a caveat though. It might seem that linear separability is good news for binary\nclassification: linear separability means that the problem is easy in some sense and that learning algorithms\nhave a clear and achievable goal. Consider the fact that the decision boundary in a linear classifier is\nindependent of the scale of the parameters. \n\nFor instance, in the above example, the decision boundary is given by t such that 1/2 = 1/(1+exp(-wt - w0)).\nSolving this simple equation for t we get t = w0/w . The decision boundary would not move a tiny bit if we multiply both w0 and w by a constant superior to 1. The boundary does not move, however, the scale does impact the likelihood in logistic regression by causing the logistic function to become more steep. If we have found such a decision boundary that all the samples from the learning database are correctly classified, we can infinitely scale the weights w and w0 , pushing the predictions closer and closer to their correct labels. The logistic function thus converges to the Heaviside step function. It is one of numerous possible instances of what is called overfitting: the model is becoming overconfident about the data and uses very large weights to describe it. There is a very simple solution to this problem: regularize the weights. The most basic regularization is to add a simple term that penalizes large weights.\n\n"},{"idx":208,"label":"66","overlay":0,"note":"It turns out that we have just built and trained a neural network made of a single neuron. 1-neuron perceptron with mean squared error loss function is equivalent to our nonlinear least squares problem.\nWhile the example we have shown here is unidimensional, it is straightforward to generalize it: we can\nfit the m-dimensional logistic function 1/(1+exp(-w^t x)),\nwhere w is a (m + 1)-parameter vector, the last element of x is the constant 1, and w^t x is the corresponding linear combination. \n\nNote that the decision boundary is always linear: it is a point in 1D, a straight line in 2D, a plane in 3D and so forth. \n\nFigure on the right shows the energy plot for the unidimensional example (note the regularization). While the function has a unique minimum, it is highly non-convex, making the numerical optimization a difficult problem.\n"},{"idx":209,"label":"66","overlay":1,"note":"It turns out that we have just built and trained a neural network made of a single neuron. 1-neuron perceptron with mean squared error loss function is equivalent to our nonlinear least squares problem.\nWhile the example we have shown here is unidimensional, it is straightforward to generalize it: we can\nfit the m-dimensional logistic function 1/(1+exp(-w^t x)),\nwhere w is a (m + 1)-parameter vector, the last element of x is the constant 1, and w^t x is the corresponding linear combination. \n\nNote that the decision boundary is always linear: it is a point in 1D, a straight line in 2D, a plane in 3D and so forth. \n\nFigure on the right shows the energy plot for the unidimensional example (note the regularization). While the function has a unique minimum, it is highly non-convex, making the numerical optimization a difficult problem.\n"},{"idx":210,"label":"67","overlay":0,"note":"Logistic regression is another technique borrowed by machine learning from the field of statistics. As before,\nthe basic idea of logistic regression consists in that the space of initial values can be divided by a linear\nboundary (i.e. a straight line) into two areas corresponding to classes. Simply answering “red” or “green” is\npretty crude — especially if there is no perfect rule. Something wich takes a noise into account, and does\nnot just give a binary answer, will often be useful. In short, we want probabilities — which means we need\nto fit a stochastic model.\nLet two possible classes encoded as y ∈ {0, 1} and assume \n\n\nwhere w is a (m + 1)-parameter vector and the last element of x is the constant 1. Here we interpret the\nsigmoid p(y = 1|x, w) as a conditional distribution of the response y, given the input variables. Follows that\n\n\nUp to this moment, there are absolutely no changes w.r.t the previous section: we use the same one-neuron perceptron. The crucial difference comes from the way we will train it. In previous section we have minimized the mean squared error loss function, implicitly assuming presence of zero-mean Gaussian noise in the labels of the dataset. Our data, however is not real-valued but binary-valued, and thus Bernoulli’s scheme is more suited for this situation. Exactly like we have made it in the first section, we can write the log-likelihood as\n\n\nTo fit the sigmoid to the data, we need to maximize the log-likelyhood. \n"},{"idx":211,"label":"67","overlay":1,"note":"Logistic regression is another technique borrowed by machine learning from the field of statistics. As before,\nthe basic idea of logistic regression consists in that the space of initial values can be divided by a linear\nboundary (i.e. a straight line) into two areas corresponding to classes. Simply answering “red” or “green” is\npretty crude — especially if there is no perfect rule. Something wich takes a noise into account, and does\nnot just give a binary answer, will often be useful. In short, we want probabilities — which means we need\nto fit a stochastic model.\nLet two possible classes encoded as y ∈ {0, 1} and assume \n\n\nwhere w is a (m + 1)-parameter vector and the last element of x is the constant 1. Here we interpret the\nsigmoid p(y = 1|x, w) as a conditional distribution of the response y, given the input variables. Follows that\n\n\nUp to this moment, there are absolutely no changes w.r.t the previous section: we use the same one-neuron perceptron. The crucial difference comes from the way we will train it. In previous section we have minimized the mean squared error loss function, implicitly assuming presence of zero-mean Gaussian noise in the labels of the dataset. Our data, however is not real-valued but binary-valued, and thus Bernoulli’s scheme is more suited for this situation. Exactly like we have made it in the first section, we can write the log-likelihood as\n\n\nTo fit the sigmoid to the data, we need to maximize the log-likelyhood. \n"},{"idx":212,"label":"67","overlay":2,"note":"Logistic regression is another technique borrowed by machine learning from the field of statistics. As before,\nthe basic idea of logistic regression consists in that the space of initial values can be divided by a linear\nboundary (i.e. a straight line) into two areas corresponding to classes. Simply answering “red” or “green” is\npretty crude — especially if there is no perfect rule. Something wich takes a noise into account, and does\nnot just give a binary answer, will often be useful. In short, we want probabilities — which means we need\nto fit a stochastic model.\nLet two possible classes encoded as y ∈ {0, 1} and assume \n\n\nwhere w is a (m + 1)-parameter vector and the last element of x is the constant 1. Here we interpret the\nsigmoid p(y = 1|x, w) as a conditional distribution of the response y, given the input variables. Follows that\n\n\nUp to this moment, there are absolutely no changes w.r.t the previous section: we use the same one-neuron perceptron. The crucial difference comes from the way we will train it. In previous section we have minimized the mean squared error loss function, implicitly assuming presence of zero-mean Gaussian noise in the labels of the dataset. Our data, however is not real-valued but binary-valued, and thus Bernoulli’s scheme is more suited for this situation. Exactly like we have made it in the first section, we can write the log-likelihood as\n\n\nTo fit the sigmoid to the data, we need to maximize the log-likelyhood. \n"},{"idx":213,"label":"68","overlay":0,"note":"All the hard decisions are made, it’s time for basic calculus. To maximize log L, we set its derivatives to 0 and obtain m + 1 nonlinear equations in w, refer to the course notes for the details of the derivation.\n\nWe can solve the system iteratively using Newton-Raphson steps, and it turns out that the Hessian matrix is positive definite.\n\n"},{"idx":214,"label":"68","overlay":1,"note":"All the hard decisions are made, it’s time for basic calculus. To maximize log L, we set its derivatives to 0 and obtain m + 1 nonlinear equations in w, refer to the course notes for the details of the derivation.\n\nWe can solve the system iteratively using Newton-Raphson steps, and it turns out that the Hessian matrix is positive definite.\n\n"},{"idx":215,"label":"68","overlay":2,"note":"All the hard decisions are made, it’s time for basic calculus. To maximize log L, we set its derivatives to 0 and obtain m + 1 nonlinear equations in w, refer to the course notes for the details of the derivation.\n\nWe can solve the system iteratively using Newton-Raphson steps, and it turns out that the Hessian matrix is positive definite.\n\n"},{"idx":216,"label":"68","overlay":3,"note":"All the hard decisions are made, it’s time for basic calculus. To maximize log L, we set its derivatives to 0 and obtain m + 1 nonlinear equations in w, refer to the course notes for the details of the derivation.\n\nWe can solve the system iteratively using Newton-Raphson steps, and it turns out that the Hessian matrix is positive definite.\n\n"},{"idx":217,"label":"68","overlay":4,"note":"All the hard decisions are made, it’s time for basic calculus. To maximize log L, we set its derivatives to 0 and obtain m + 1 nonlinear equations in w, refer to the course notes for the details of the derivation.\n\nWe can solve the system iteratively using Newton-Raphson steps, and it turns out that the Hessian matrix is positive definite.\n\n"},{"idx":218,"label":"69","overlay":0,"note":"Okay, now we have mastered the art of binary classification with linear decision boundaries. What about\nnonlinear boundaries? Refer to the right image for an illustration. A straightforward way to do\nit is to plug something nonlinear (e.g. a polynomial) instead of −w^t x. It has been done, however the problem is that such a prior is hard to put on the data; moreover, the optimization scheme is different for every choice of function. Here neural networks come handy.\n\n"},{"idx":219,"label":"69","overlay":1,"note":"Okay, now we have mastered the art of binary classification with linear decision boundaries. What about\nnonlinear boundaries? Refer to the right image for an illustration. A straightforward way to do\nit is to plug something nonlinear (e.g. a polynomial) instead of −w^t x. It has been done, however the problem is that such a prior is hard to put on the data; moreover, the optimization scheme is different for every choice of function. Here neural networks come handy.\n\n"},{"idx":220,"label":"70","overlay":0,"note":"So, for a linear decision boundary we have trained the simplest possible network built from a single neuron.\n\nOur last example in this chapter is a regular perceptron made of 3 neurons: two neurons in the hidden layer\nand one output neuron. You can see the topology in the right image. The input is the same m as in all classification examples throughout this chapter: we have {(xi , yi)}ni=1 as the input, where xi ∈ R and yi ∈ {0, 1}. \n\nThe loss function E is parameterized by three (m + 1)-component vectors u, v and w. For the lack of better alternative, we can minimize E by a gradient descent. The gradient of the loss function with respect to each weight can be calculated by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this is an example of dynamic programming. \n\n[show code]\n\n"},{"idx":221,"label":"70","overlay":1,"note":"So, for a linear decision boundary we have trained the simplest possible network built from a single neuron.\n\nOur last example in this chapter is a regular perceptron made of 3 neurons: two neurons in the hidden layer\nand one output neuron. You can see the topology in the right image. The input is the same m as in all classification examples throughout this chapter: we have {(xi , yi)}ni=1 as the input, where xi ∈ R and yi ∈ {0, 1}. \n\nThe loss function E is parameterized by three (m + 1)-component vectors u, v and w. For the lack of better alternative, we can minimize E by a gradient descent. The gradient of the loss function with respect to each weight can be calculated by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this is an example of dynamic programming. \n\n[show code]\n\n"},{"idx":222,"label":"70","overlay":2,"note":"So, for a linear decision boundary we have trained the simplest possible network built from a single neuron.\n\nOur last example in this chapter is a regular perceptron made of 3 neurons: two neurons in the hidden layer\nand one output neuron. You can see the topology in the right image. The input is the same m as in all classification examples throughout this chapter: we have {(xi , yi)}ni=1 as the input, where xi ∈ R and yi ∈ {0, 1}. \n\nThe loss function E is parameterized by three (m + 1)-component vectors u, v and w. For the lack of better alternative, we can minimize E by a gradient descent. The gradient of the loss function with respect to each weight can be calculated by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this is an example of dynamic programming. \n\n[show code]\n\n"},{"idx":223,"label":"71","overlay":0,"note":"Let us deconstruct the network to understand how the nonlinearity of the boundary is obtained, A perceptron with a hidden layer combines sigmoids from the hidden layer and applies a sigmoid over it. In our example the data is two-dimensional; for the sake of simplicity, imagine that the hidden layer neurons produce unit steps instead of sigmoids. \n\nLet us suppose that all the weights are equal to 1, then the sum of these steps separates the data plane into four quadrants where the sum is equal to 0, 1 and 2. By applying a unit step over this result, we can isolate one particular quadrant, effectively creating a non-linear decision boundary. It is the last layer activation function that makes the difference. If we would remove this, the decision boundary would remain linear. \n\nSo, we can choose the type of the decision boundary by adapting the topology of the network, but be aware that you are entering the black magic realm! Generally speaking, there is no whatsoever guarantee of convergence; and even this simplest network has too much degrees of freedom for our training dataset. We can negate all the weights without affecting the decision boundary. . .\n"},{"idx":224,"label":"71","overlay":1,"note":"Let us deconstruct the network to understand how the nonlinearity of the boundary is obtained, A perceptron with a hidden layer combines sigmoids from the hidden layer and applies a sigmoid over it. In our example the data is two-dimensional; for the sake of simplicity, imagine that the hidden layer neurons produce unit steps instead of sigmoids. \n\nLet us suppose that all the weights are equal to 1, then the sum of these steps separates the data plane into four quadrants where the sum is equal to 0, 1 and 2. By applying a unit step over this result, we can isolate one particular quadrant, effectively creating a non-linear decision boundary. It is the last layer activation function that makes the difference. If we would remove this, the decision boundary would remain linear. \n\nSo, we can choose the type of the decision boundary by adapting the topology of the network, but be aware that you are entering the black magic realm! Generally speaking, there is no whatsoever guarantee of convergence; and even this simplest network has too much degrees of freedom for our training dataset. We can negate all the weights without affecting the decision boundary. . .\n"},{"idx":225,"label":"72","overlay":0,"note":"As I have already said, it surprising to witness the existence of two fighting religions: neural networks is a gift of God versus \"neural networks is a no-no\".\n\nObviously, we cannot fit all of the data with a straight line, or a plane, but with powerful feature\nextractors, we may be able to reduce our problem to a much simpler one. To put it into perspective, this is\nwhat neural networks do effectively, the only difference being that we use some nonlinearity as the activation\nfunction in the last layer. If we would remove this, we could look at the last layer of the neural network as\na least squares problem, i.e. fitting a plane on the data (activations from previous layers).\n"},{"idx":226,"label":"73","overlay":0,"note":"This concludes my presentation. Obviously it is not possible to master even the few examples I have provided from the presentation alone. Even if you have paid a full attention, the presentation is way too rapid on most aspects. This is why we give you the source code to play with. Read the course notes, check the source code, modify the source code. Have fun!"},{"idx":227,"label":"73","overlay":1,"note":"This concludes my presentation. Obviously it is not possible to master even the few examples I have provided from the presentation alone. Even if you have paid a full attention, the presentation is way too rapid on most aspects. This is why we give you the source code to play with. Read the course notes, check the source code, modify the source code. Have fun!"}]}